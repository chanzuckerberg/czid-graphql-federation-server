// Jest Snapshot v1, https://goo.gl/fbAQLP

exports[`CZ ID graphQL federation generated schema should generate a valid schema 1`] = `
"schema {
  query: Query
  mutation: Mutation
}

directive @example(value: ObjMap) repeatable on ENUM | FIELD_DEFINITION | INPUT_OBJECT | OBJECT | SCALAR

directive @globalOptions(sourceName: String, endpoint: String, operationHeaders: ObjMap, queryStringOptions: ObjMap, queryParams: ObjMap) on OBJECT

directive @httpOperation(path: String, operationSpecificHeaders: ObjMap, httpMethod: HTTPMethod, isBinary: Boolean, requestBaseBody: ObjMap, queryParamArgMap: ObjMap, queryStringOptionsByParam: ObjMap) on FIELD_DEFINITION

type Query @globalOptions(sourceName: "CZIDREST", endpoint: "http://web:3001/") {
  appConfig(id: ID!): AppConfig
  pathogenList(version: String): PathogenList!
  project(id: Int!): Project!
  sample(sampleId: Int!): Sample!
  sampleReadsStats(sampleIds: [String!]!): SampleReadsStatsList!
  samplesList(annotations: [Annotation!], basic: Boolean, domain: String, hostIds: [Int!], limit: Int, listAllIds: Boolean, location: String, locationV2: [String!], offset: Int, orderBy: String, orderDir: String, projectId: Int, requestedSampleIds: [Int!], sampleIds: [Int!], searchString: String, taxIds: [Int!], taxLevels: [String!], thresholdFilterInfo: String, time: [String!], tissue: [String!], visibility: [String!], workflow: String): SampleList!
  user(archetypes: String!, email: String!, institution: String!, name: String!, role: Int!, segments: String!): User!
  node(
    """The ID of the object."""
    id: GlobalID!
  ): Node!
  nodes(
    """The IDs of the objects."""
    ids: [GlobalID!]!
  ): [Node!]!
  files(where: FileWhereClause = null): [File!]!
  samples(where: SampleWhereClause = null, orderBy: [SampleOrderByClause!] = []): [Sample!]!
  sequencingReads(where: SequencingReadWhereClause = null, orderBy: [SequencingReadOrderByClause!] = []): [SequencingRead!]!
  genomicRanges(where: GenomicRangeWhereClause = null, orderBy: [GenomicRangeOrderByClause!] = []): [GenomicRange!]!
  referenceGenomes(where: ReferenceGenomeWhereClause = null, orderBy: [ReferenceGenomeOrderByClause!] = []): [ReferenceGenome!]!
  accessions(where: AccessionWhereClause = null, orderBy: [AccessionOrderByClause!] = []): [Accession!]!
  hostOrganisms(where: HostOrganismWhereClause = null, orderBy: [HostOrganismOrderByClause!] = []): [HostOrganism!]!
  metadatas(where: MetadatumWhereClause = null, orderBy: [MetadatumOrderByClause!] = []): [Metadatum!]!
  consensusGenomes(where: ConsensusGenomeWhereClause = null, orderBy: [ConsensusGenomeOrderByClause!] = []): [ConsensusGenome!]!
  metricsConsensusGenomes(where: MetricConsensusGenomeWhereClause = null, orderBy: [MetricConsensusGenomeOrderByClause!] = []): [MetricConsensusGenome!]!
  taxa(where: TaxonWhereClause = null, orderBy: [TaxonOrderByClause!] = []): [Taxon!]!
  upstreamDatabases(where: UpstreamDatabaseWhereClause = null, orderBy: [UpstreamDatabaseOrderByClause!] = []): [UpstreamDatabase!]!
  indexFiles(where: IndexFileWhereClause = null, orderBy: [IndexFileOrderByClause!] = []): [IndexFile!]!
  bulkDownloads(input: queryInput_bulkDownloads_input_Input): [query_bulkDownloads_items] @httpOperation(path: "/bulk_downloads?searchBy=&n=", httpMethod: GET)
  samplesAggregate(where: SampleWhereClause = null): SampleAggregate!
  sequencingReadsAggregate(where: SequencingReadWhereClause = null): SequencingReadAggregate!
  genomicRangesAggregate(where: GenomicRangeWhereClause = null): GenomicRangeAggregate!
  referenceGenomesAggregate(where: ReferenceGenomeWhereClause = null): ReferenceGenomeAggregate!
  accessionsAggregate(where: AccessionWhereClause = null): AccessionAggregate!
  hostOrganismsAggregate(where: HostOrganismWhereClause = null): HostOrganismAggregate!
  metadatasAggregate(where: MetadatumWhereClause = null): MetadatumAggregate!
  consensusGenomesAggregate(where: ConsensusGenomeWhereClause = null): ConsensusGenomeAggregate!
  metricsConsensusGenomesAggregate(where: MetricConsensusGenomeWhereClause = null): MetricConsensusGenomeAggregate!
  taxaAggregate(where: TaxonWhereClause = null): TaxonAggregate!
  upstreamDatabasesAggregate(where: UpstreamDatabaseWhereClause = null): UpstreamDatabaseAggregate!
  indexFilesAggregate(where: IndexFileWhereClause = null): IndexFileAggregate!
  bulkDownloadsAggregate(where: BulkDownloadWhereClause = null): BulkDownloadAggregate!
  workflowRuns(input: queryInput_workflowRuns_input_Input): [query_workflowRuns_items] @httpOperation(path: "/workflow_runs.json", httpMethod: POST)
  workflows(where: WorkflowWhereClause = null, orderBy: [WorkflowOrderByClause!] = []): [Workflow!]!
  workflowRunSteps(where: WorkflowRunStepWhereClause = null, orderBy: [WorkflowRunStepOrderByClause!] = []): [WorkflowRunStep!]!
  workflowRunEntityInputs(where: WorkflowRunEntityInputWhereClause = null, orderBy: [WorkflowRunEntityInputOrderByClause!] = []): [WorkflowRunEntityInput!]!
  workflowVersions(where: WorkflowVersionWhereClause = null, orderBy: [WorkflowVersionOrderByClause!] = []): [WorkflowVersion!]!
  workflowRunsAggregate(where: WorkflowRunWhereClause = null): WorkflowRunAggregate!
  workflowsAggregate(where: WorkflowWhereClause = null): WorkflowAggregate!
  workflowRunStepsAggregate(where: WorkflowRunStepWhereClause = null): WorkflowRunStepAggregate!
  workflowRunEntityInputsAggregate(where: WorkflowRunEntityInputWhereClause = null): WorkflowRunEntityInputAggregate!
  workflowVersionsAggregate(where: WorkflowVersionWhereClause = null): WorkflowVersionAggregate!
  AmrDeprecatedResults(sampleId: String): AmrDeprecatedResults @httpOperation(path: "/samples/{args.sampleId}/amr.json", operationSpecificHeaders: "{\\"Cookie\\":\\"{context.headers['cookie']}\\"}", httpMethod: GET)
  AmrWorkflowResults(workflowRunId: String): AmrWorkflowResults @httpOperation(path: "/workflow_runs/{args.workflowRunId}/results", httpMethod: GET)
  Background(snapshotLinkId: String): Background @httpOperation(path: "/pub/{args.snapshotLinkId}/backgrounds.json", httpMethod: GET)
  BulkDownloadCGOverview(input: queryInput_BulkDownloadCGOverview_input_Input): ConsensusGenomeOverviewRows @httpOperation(path: "/bulk_downloads", httpMethod: POST)
  fedConsensusGenomes(input: queryInput_fedConsensusGenomes_input_Input): [query_fedConsensusGenomes_items] @httpOperation(path: "/workflow_runs.json", httpMethod: GET)
  ConsensusGenomeWorkflowResults(workflowRunId: String): ConsensusGenomeWorkflowResults @httpOperation(path: "/workflow_runs/{args.workflowRunId}/results", httpMethod: GET)
  CoverageVizSummary(snapshotLinkId: String, sampleId: String): [query_CoverageVizSummary_items] @httpOperation(path: "/pub/{args.snapshotLinkId}/samples/{args.sampleId}/coverage_viz_summary", httpMethod: GET)
  MetadataFields(snapshotLinkId: String, input: queryInput_MetadataFields_input_Input): [query_MetadataFields_items] @httpOperation(path: "/pub/{args.snapshotLinkId}/samples/metadata_fields", operationSpecificHeaders: "{\\"Cookie\\":\\"{context.headers['cookie']}\\"}", httpMethod: POST)
  SampleMetadata(snapshotLinkId: String, sampleId: String, input: queryInput_SampleMetadata_input_Input): SampleMetadata @httpOperation(path: "/pub/{args.snapshotLinkId}/samples/{args.sampleId}/metadata", httpMethod: GET)
  MngsWorkflowResults(snapshotLinkId: String, sampleId: String, workflowVersionId: String, _backgroundId: String): MngsWorkflowResults @httpOperation(path: "/pub/{args.snapshotLinkId}/samples/{args.sampleId}.json", httpMethod: GET) @httpOperation(path: "/pub/{args.snapshotLinkId}/samples/{args.sampleId}/report_v2?&id={args.sampleId}&pipeline_version={args.workflowVersionId}&background={args._backgroundId}&merge_nt_nr=false", httpMethod: GET)
  Pathogens(snapshotLinkId: String, sampleId: String, workflowVersionId: String): [query_Pathogens_items] @httpOperation(path: "/pub/{args.snapshotLinkId}/samples/{args.sampleId}/report_v2?&id={args.sampleId}&pipeline_version={args.workflowVersionId}&merge_nt_nr=false", httpMethod: GET)
  PersistedBackground(projectId: String): PersistedBackground @httpOperation(path: "/persisted_backgrounds/{args.projectId}", operationSpecificHeaders: "{\\"Cookie\\":\\"{context.headers['cookie']}\\"}", httpMethod: GET)
  PipelineData(sampleId: String, workflowVersionId: String): PipelineData @httpOperation(path: "/samples/{args.sampleId}/pipeline_viz/{args.workflowVersionId}.json", operationSpecificHeaders: "{\\"Cookie\\":\\"{context.headers['cookie']}\\"}", httpMethod: GET)
  fedSamples(input: queryInput_fedSamples_input_Input): [query_fedSamples_items] @httpOperation(path: "/workflow_runs.json", httpMethod: GET)
  fedSequencingReads(input: queryInput_fedSequencingReads_input_Input): [query_fedSequencingReads_items] @httpOperation(path: "/workflow_runs.json", httpMethod: GET)
  Taxons(snapshotLinkId: String, sampleId: String, workflowVersionId: String): [query_Taxons_items] @httpOperation(path: "/pub/{args.snapshotLinkId}/samples/{args.sampleId}/report_v2?&id={args.sampleId}&pipeline_version={args.workflowVersionId}&merge_nt_nr=false", httpMethod: GET)
  TaxonDist(backgroundId: String, taxonId: String): TaxonDist @httpOperation(path: "/backgrounds/{args.backgroundId}/show_taxon_dist.json?taxid={args.taxonId}", operationSpecificHeaders: "{\\"Cookie\\":\\"{context.headers['cookie']}\\"}", httpMethod: GET)
  UserBlastAnnotations(sampleId: String, workflowVersionId: String): [query_UserBlastAnnotations_items] @httpOperation(path: "/samples/{args.sampleId}/report_v2?&id={args.sampleId}&pipeline_version={args.workflowVersionId}&merge_nt_nr=false", httpMethod: GET)
  ValidateUserCanDeleteObjects(input: queryInput_ValidateUserCanDeleteObjects_input_Input): ValidateUserCanDeleteObjects @httpOperation(path: "/samples/validate_user_can_delete_objects.json", httpMethod: POST)
  fedWorkflowRuns(input: queryInput_workflowRuns_input_Input): [query_workflowRuns_items] @httpOperation(path: "/workflow_runs.json", httpMethod: POST)
  fedWorkflowRunsAggregate(input: queryInput_fedWorkflowRunsAggregate_input_Input): [query_fedWorkflowRunsAggregate_items] @httpOperation(path: "/projects.json", httpMethod: GET)
  ZipLink(workflowRunId: String): ZipLink @httpOperation(path: "/workflow_runs/{args.workflowRunId}/zip_link.json", httpMethod: GET)
  GraphQLFederationVersion: GraphQLFederationVersion
}

type Mutation {
  createUser(archetypes: String, email: String!, institution: String, name: String, role: Int, segments: String, sendActivation: Boolean): CreateUserPayload!
  createFile(entityId: ID!, entityFieldName: String!, file: FileCreate!): File!
  uploadFile(entityId: ID!, entityFieldName: String!, file: FileUpload!, expiration: Int! = 3600): MultipartUploadResponse!
  uploadTemporaryFile(expiration: Int! = 3600): MultipartUploadResponse!
  markUploadComplete(fileId: ID!): File!
  concatenateFiles(ids: [UUID!]!): SignedURL!
  createSample(input: SampleCreateInput!): Sample!
  updateSample(input: SampleUpdateInput!, where: SampleWhereClauseMutations!): [Sample!]!
  deleteSample(where: SampleWhereClauseMutations!): [Sample!]!
  createSequencingRead(input: SequencingReadCreateInput!): SequencingRead!
  updateSequencingRead(input: SequencingReadUpdateInput!, where: SequencingReadWhereClauseMutations!): [SequencingRead!]!
  deleteSequencingRead(where: SequencingReadWhereClauseMutations!): [SequencingRead!]!
  createGenomicRange(input: GenomicRangeCreateInput!): GenomicRange!
  deleteGenomicRange(where: GenomicRangeWhereClauseMutations!): [GenomicRange!]!
  createReferenceGenome(input: ReferenceGenomeCreateInput!): ReferenceGenome!
  updateReferenceGenome(input: ReferenceGenomeUpdateInput!, where: ReferenceGenomeWhereClauseMutations!): [ReferenceGenome!]!
  deleteReferenceGenome(where: ReferenceGenomeWhereClauseMutations!): [ReferenceGenome!]!
  createAccession(input: AccessionCreateInput!): Accession!
  updateAccession(input: AccessionUpdateInput!, where: AccessionWhereClauseMutations!): [Accession!]!
  deleteAccession(where: AccessionWhereClauseMutations!): [Accession!]!
  createHostOrganism(input: HostOrganismCreateInput!): HostOrganism!
  updateHostOrganism(input: HostOrganismUpdateInput!, where: HostOrganismWhereClauseMutations!): [HostOrganism!]!
  deleteHostOrganism(where: HostOrganismWhereClauseMutations!): [HostOrganism!]!
  createMetadatum(input: MetadatumCreateInput!): Metadatum!
  updateMetadatum(input: MetadatumUpdateInput!, where: MetadatumWhereClauseMutations!): [Metadatum!]!
  deleteMetadatum(where: MetadatumWhereClauseMutations!): [Metadatum!]!
  createConsensusGenome(input: ConsensusGenomeCreateInput!): ConsensusGenome!
  deleteConsensusGenome(where: ConsensusGenomeWhereClauseMutations!): [ConsensusGenome!]!
  createMetricConsensusGenome(input: MetricConsensusGenomeCreateInput!): MetricConsensusGenome!
  deleteMetricConsensusGenome(where: MetricConsensusGenomeWhereClauseMutations!): [MetricConsensusGenome!]!
  createTaxon(input: TaxonCreateInput!): Taxon!
  updateTaxon(input: TaxonUpdateInput!, where: TaxonWhereClauseMutations!): [Taxon!]!
  deleteTaxon(where: TaxonWhereClauseMutations!): [Taxon!]!
  createUpstreamDatabase(input: UpstreamDatabaseCreateInput!): UpstreamDatabase!
  updateUpstreamDatabase(input: UpstreamDatabaseUpdateInput!, where: UpstreamDatabaseWhereClauseMutations!): [UpstreamDatabase!]!
  deleteUpstreamDatabase(where: UpstreamDatabaseWhereClauseMutations!): [UpstreamDatabase!]!
  createIndexFile(input: IndexFileCreateInput!): IndexFile!
  updateIndexFile(input: IndexFileUpdateInput!, where: IndexFileWhereClauseMutations!): [IndexFile!]!
  deleteIndexFile(where: IndexFileWhereClauseMutations!): [IndexFile!]!
  createBulkDownload(input: BulkDownloadCreateInput!): BulkDownload!
  deleteBulkDownload(where: BulkDownloadWhereClauseMutations!): [BulkDownload!]!
  createWorkflowRun(input: RunWorkflowVersionInput!): WorkflowRun!
  updateWorkflowRun(input: WorkflowRunUpdateInput!, where: WorkflowRunWhereClauseMutations!): [WorkflowRun!]!
  deleteWorkflowRun(where: WorkflowRunWhereClauseMutations!): [WorkflowRun!]!
  createWorkflow(input: WorkflowCreateInput!): Workflow!
  updateWorkflow(input: WorkflowUpdateInput!, where: WorkflowWhereClauseMutations!): [Workflow!]!
  deleteWorkflow(where: WorkflowWhereClauseMutations!): [Workflow!]!
  createWorkflowRunStep(input: WorkflowRunStepCreateInput!): WorkflowRunStep!
  updateWorkflowRunStep(input: WorkflowRunStepUpdateInput!, where: WorkflowRunStepWhereClauseMutations!): [WorkflowRunStep!]!
  deleteWorkflowRunStep(where: WorkflowRunStepWhereClauseMutations!): [WorkflowRunStep!]!
  createWorkflowRunEntityInput(input: WorkflowRunEntityInputCreateInput!): WorkflowRunEntityInput!
  deleteWorkflowRunEntityInput(where: WorkflowRunEntityInputWhereClauseMutations!): [WorkflowRunEntityInput!]!
  createWorkflowVersion(input: WorkflowVersionCreateInput!): WorkflowVersion!
  deleteWorkflowVersion(where: WorkflowVersionWhereClauseMutations!): [WorkflowVersion!]!
  runWorkflowVersion(input: RunWorkflowVersionInput!): WorkflowRun!
  runWorkflowRun(workflowRunId: ID!): WorkflowRun!
  CreateBulkDownload(input: mutationInput_CreateBulkDownload_input_Input): JSON @httpOperation(path: "/bulk_download", httpMethod: POST)
  DeleteSamples(input: mutationInput_DeleteSamples_input_Input): DeleteSamples @httpOperation(path: "/samples/bulk_delete", httpMethod: POST)
  UpdateSampleNotes(sampleId: String, input: mutationInput_UpdateSampleNotes_input_Input): UpdateSampleNotes @httpOperation(path: "/samples/{args.sampleId}/save_metadata", operationSpecificHeaders: "{\\"Cookie\\":\\"{context.headers['cookie']}\\"}", httpMethod: POST)
  UpdateSampleName(sampleId: String, input: mutationInput_UpdateSampleNotes_input_Input): UpdateSampleName @httpOperation(path: "/samples/{args.sampleId}/save_metadata", operationSpecificHeaders: "{\\"Cookie\\":\\"{context.headers['cookie']}\\"}", httpMethod: POST)
  KickoffWGSWorkflow(sampleId: String, input: mutationInput_KickoffWGSWorkflow_input_Input): [mutation_KickoffWGSWorkflow_items] @httpOperation(path: "/samples/{args.sampleId}/kickoff_workflow", operationSpecificHeaders: "{\\"Cookie\\":\\"{context.headers['cookie']}\\"}", httpMethod: POST)
  KickoffAMRWorkflow(sampleId: String, input: mutationInput_KickoffAMRWorkflow_input_Input): [mutation_KickoffWGSWorkflow_items] @httpOperation(path: "/samples/{args.sampleId}/kickoff_workflow", operationSpecificHeaders: "{\\"Cookie\\":\\"{context.headers['cookie']}\\"}", httpMethod: POST)
  UpdateMetadata(sampleId: String, input: mutationInput_UpdateMetadata_input_Input): UpdateMetadataReponse @httpOperation(path: "/samples/{args.sampleId}/save_metadata_v2", operationSpecificHeaders: "{\\"Cookie\\":\\"{context.headers['cookie']}\\"}", httpMethod: POST)
}

enum AlignmentTool {
  bowtie2
  minimap2
  czid_index_generation
}

input AlignmentToolEnumComparators {
  _eq: AlignmentTool
  _neq: AlignmentTool
  _in: [AlignmentTool!]
  _nin: [AlignmentTool!]
  _gt: AlignmentTool
  _gte: AlignmentTool
  _lt: AlignmentTool
  _lte: AlignmentTool
  _is_null: AlignmentTool
}

input BoolComparators {
  _eq: Int
  _neq: Int
  _in: [Int!]
  _nin: [Int!]
  _gt: Int
  _gte: Int
  _lt: Int
  _lte: Int
  _is_null: Int
}

type ConsensusGenome implements EntityInterface & Node {
  """The Globally Unique ID of this object"""
  _id: GlobalID!
  id: ID!
  producingRunId: Int
  ownerUserId: Int!
  collectionId: Int!
  taxon(where: TaxonWhereClause = null): Taxon
  sequenceRead(where: SequencingReadWhereClause = null): SequencingRead
  referenceGenome(where: ReferenceGenomeWhereClause = null): ReferenceGenome
  sequenceId: ID
  sequence(where: FileWhereClause = null): File
  intermediateOutputsId: ID
  intermediateOutputs(where: FileWhereClause = null): File
  metrics(
    where: MetricConsensusGenomeWhereClause = null
    """Returns the items in the list that come before the specified cursor."""
    before: String = null
    """Returns the items in the list that come after the specified cursor."""
    after: String = null
    """Returns the items in the list that come before the specified cursor."""
    before: String = null
    """Returns the first n items from the list."""
    first: Int = null
    """Returns the items in the list that come after the specified cursor."""
    last: Int = null
  ): MetricConsensusGenomeConnection!
  metricsAggregate(where: MetricConsensusGenomeWhereClause = null): MetricConsensusGenomeAggregate
}

type AccessionAggregate {
  aggregate: [AccessionAggregateFunctions!]
}

type ConsensusGenomeAggregateFunctions {
  sum: ConsensusGenomeNumericalColumns
  avg: ConsensusGenomeNumericalColumns
  min: ConsensusGenomeMinMaxColumns
  max: ConsensusGenomeMinMaxColumns
  stddev: ConsensusGenomeNumericalColumns
  variance: ConsensusGenomeNumericalColumns
  count(distinct: Boolean = false, columns: ConsensusGenomeCountColumns = null): Int
}

"""A connection to a list of items."""
type ConsensusGenomeConnection {
  """Pagination data for this connection"""
  pageInfo: PageInfo!
  """Contains the nodes in this connection"""
  edges: [ConsensusGenomeEdge!]!
}

enum ConsensusGenomeCountColumns {
  taxon
  sequence_read
  reference_genome
  sequence
  intermediate_outputs
  metrics
  entity_id
  id
  producing_run_id
  owner_user_id
  collection_id
}

input AccessionCreateInput {
  accessionId: String!
  accessionName: String!
  upstreamDatabaseId: ID!
  producingRunId: ID = null
  collectionId: Int!
  taxonId: ID!
  sequenceReadId: ID!
  referenceGenomeId: ID!
  sequenceId: ID = null
  intermediateOutputsId: ID = null
}

"""An edge in a connection."""
type AccessionEdge {
  """A cursor for use in pagination"""
  cursor: String!
  """The item at the end of the edge"""
  node: Accession!
}

type ConsensusGenomeMinMaxColumns {
  producingRunId: Int
  ownerUserId: Int
  collectionId: Int
}

type ConsensusGenomeNumericalColumns {
  producingRunId: Int
  ownerUserId: Int
  collectionId: Int
}

input ConsensusGenomeUpdateInput {
  collectionId: Int = null
  taxonId: ID = null
  sequenceReadId: ID = null
  referenceGenomeId: ID = null
  sequenceId: ID = null
  intermediateOutputsId: ID = null
}

input ConsensusGenomeWhereClause {
  id: UUIDComparators
  producingRunId: IntComparators
  ownerUserId: IntComparators
  collectionId: IntComparators
  taxon: TaxonWhereClause
  sequenceRead: SequencingReadWhereClause
  referenceGenome: ReferenceGenomeWhereClause
  metrics: MetricConsensusGenomeWhereClause
}

input AccessionWhereClauseMutations {
  id: UUIDComparators
}

type ConsensusGenomeWorkflowResults {
  metric_consensus_genome: query_ConsensusGenomeWorkflowResults_metric_consensus_genome
  reference_genome: query_ConsensusGenomeWorkflowResults_reference_genome
}

input BoolComparators {
  _eq: Int
  _neq: Int
  _in: [Int!]
  _nin: [Int!]
  _gt: Int
  _gte: Int
  _lt: Int
  _lte: Int
  _is_null: Int
}

type BulkDownload implements EntityInterface & Node {
  """The Globally Unique ID of this object"""
  _id: GlobalID!
  collectionId: Int!
  id: ID!
  producingRunId: Int
  ownerUserId: Int!
  collectionId: Int!
  sequencingRead(where: SequencingReadWhereClause = null): SequencingRead
  sequence: String!
}

type ConsensusGenomeAggregate {
  aggregate: [ConsensusGenomeAggregateFunctions!]
}

type ContigAggregateFunctions {
  sum: ContigNumericalColumns
  avg: ContigNumericalColumns
  min: ContigMinMaxColumns
  max: ContigMinMaxColumns
  stddev: ContigNumericalColumns
  variance: ContigNumericalColumns
  count(distinct: Boolean = false, columns: ContigCountColumns = null): Int
}

"""A connection to a list of items."""
type ContigConnection {
  """Pagination data for this connection"""
  pageInfo: PageInfo!
  """Contains the nodes in this connection"""
  edges: [ContigEdge!]!
}

enum ContigCountColumns {
  sequencing_read
  sequence
  entity_id
  id
  producing_run_id
  owner_user_id
  collection_id
}

input ConsensusGenomeCreateInput {
  taxonId: ID!
  sequencingReadId: ID!
  referenceGenomeId: ID = null
  accessionId: ID = null
  producingRunId: ID = null
  collectionId: Int!
  sequencingReadId: ID = null
  sequence: String!
}

"""An edge in a connection."""
type ConsensusGenomeEdge {
  """A cursor for use in pagination"""
  cursor: String!
  """The item at the end of the edge"""
  node: ConsensusGenome!
}

type ContigMinMaxColumns {
  producingRunId: Int
  ownerUserId: Int
  collectionId: Int
  sequence: String
}

type ContigNumericalColumns {
  producingRunId: Int
  ownerUserId: Int
  collectionId: Int
}

input ContigUpdateInput {
  collectionId: Int = null
  sequencingReadId: ID = null
  sequence: String = null
}

input ContigWhereClause {
  id: UUIDComparators
  producingRunId: IntComparators
  ownerUserId: IntComparators
  collectionId: IntComparators
  sequencingRead: SequencingReadWhereClause
  sequence: StrComparators
}

input ConsensusGenomeWhereClauseMutations {
  id: UUIDComparators
}

"""Autogenerated return type of CreateUser."""
type CreateUserPayload {
  archetypes: String
  email: String
  institution: String
  name: String
  role: Int
  segments: String
  sendActivation: Boolean
}

"""Date with time (isoformat)"""
scalar DateTime

input DatetimeComparators {
  _eq: DateTime
  _gt: DateTime
  _gte: DateTime
  _in: [DateTime!]
  _is_null: DateTime
  _lt: DateTime
  _lte: DateTime
  _neq: DateTime
  _nin: [DateTime!]
}

type DbSample {
  alignmentConfigName: String
  basespaceAccessToken: String
  clientUpdatedAt: ISO8601DateTime
  createdAt: ISO8601DateTime!
  dagVars: String
  doNotProcess: Boolean!
  hostGenomeId: Int
  hostGenomeName: String
  id: Int!
  initialWorkflow: String!
  inputFiles: [InputFile!]!
  maxInputFragments: Int
  name: String
  pipelineBranch: String
  pipelineCommit: String
  pipelineExecutionStrategy: String
  privateUntil: ISO8601DateTime
  projectId: Int
  s3Bowtie2IndexPath: String
  s3PreloadResultPath: String
  s3StarIndexPath: String
  sampleNotes: String
  status: String
  subsample: Int
  updatedAt: ISO8601DateTime!
  uploadError: String
  uploadedFromBasespace: Int!
  useTaxonWhitelist: Boolean!
  userId: Int!
  webCommit: String
}

type DeleteSamples {
  deleted_workflow_ids: [Int]
  error: String
}

type DerivedSampleOutput {
  hostGenomeName: String!
  pipelineRun: PipelineRun
  projectName: String!
  summaryStats: SampleSummaryStats
}

type Entity {
  collectionId: Int!
  id: ID!
  ownerUserId: Int!
  producingRunId: ID!
  type: String!
}

interface EntityInterface implements Node {
  """The Globally Unique ID of this object"""
  _id: GlobalID!
}

input EntityWhereClause {
  collectionId: IntComparators
  entityId: UUIDComparators
  id: UUIDComparators
  ownerUserId: IntComparators
  producingRunId: IntComparators
}

type File {
  compressionType: Int
  downloadLink(expiration: Int! = 3600): SignedURL
  entity(where: EntityWhereClause = null): Entity
  entityFieldName: String!
  entityId: ID!
  fileFormat: String!
  id: ID!
  namespace: String!
  path: String!
  protocol: String!
  size: Int
  downloadLink(expiration: Int! = 3600): SignedURL
  contents: String
}

enum FileAccessProtocol {
  s3
}

input FileCreate {
  compressionType: String = null
  fileFormat: String!
  name: String!
  namespace: String!
  path: String!
  protocol: String!
}

enum FileStatus {
  FAILED
  PENDING
  SUCCESS
}

input FileStatusEnumComparators {
  _eq: FileStatus
  _gt: FileStatus
  _gte: FileStatus
  _in: [FileStatus!]
  _is_null: FileStatus
  _lt: FileStatus
  _lte: FileStatus
  _neq: FileStatus
  _nin: [FileStatus!]
}

input FileUpload {
  compressionType: String = null
  fileFormat: String!
  name: String!
}

input FileWhereClause {
  compressionType: StrComparators
  entityFieldName: StrComparators
  entityId: UUIDComparators
  fileFormat: StrComparators
  id: UUIDComparators
  namespace: StrComparators
  path: StrComparators
  protocol: StrComparators
  size: IntComparators
  status: FileStatusEnumComparators
}

input FloatComparators {
  _eq: Float
  _gt: Float
  _gte: Float
  _in: [Float!]
  _is_null: Float
  _lt: Float
  _lte: Float
  _neq: Float
  _nin: [Float!]
}

type GenomicRange implements EntityInterface & Node {
  """The Globally Unique ID of this object"""
  _id: GlobalID!
  collectionId: Int!
  file(where: FileWhereClause = null): File
  fileId: ID
  id: ID!
  producingRunId: Int
  ownerUserId: Int!
  collectionId: Int!
  referenceGenome(where: ReferenceGenomeWhereClause = null): ReferenceGenome
  fileId: ID
  file(where: FileWhereClause = null): File
  sequencingReads(
    where: SequencingReadWhereClause = null
    """Returns the items in the list that come before the specified cursor."""
    before: String = null
    """Returns the items in the list that come after the specified cursor."""
    after: String = null
    """Returns the items in the list that come before the specified cursor."""
    before: String = null
    """Returns the first n items from the list."""
    first: Int = null
    """Returns the items in the list that come after the specified cursor."""
    last: Int = null
    where: SequencingReadWhereClause = null
  ): SequencingReadConnection!
  sequencingReadsAggregate(where: SequencingReadWhereClause = null): SequencingReadAggregate
  producingRunId: ID
  ownerUserId: Int!
  collectionId: Int!
  createdAt: DateTime!
  updatedAt: DateTime
}

type GenomicRangeAggregate {
  aggregate: [GenomicRangeAggregateFunctions!]
}

type GenomicRangeAggregateFunctions {
  avg: GenomicRangeNumericalColumns
  min: GenomicRangeMinMaxColumns
  max: GenomicRangeMinMaxColumns
  stddev: GenomicRangeNumericalColumns
  sum: GenomicRangeNumericalColumns
  variance: GenomicRangeNumericalColumns
  count(distinct: Boolean = false, columns: GenomicRangeCountColumns = null): Int
}

"""A connection to a list of items."""
type GenomicRangeConnection {
  """Pagination data for this connection"""
  pageInfo: PageInfo!
  """Contains the nodes in this connection"""
  edges: [GenomicRangeEdge!]!
}

enum GenomicRangeCountColumns {
  reference_genome
  file
  sequencing_reads
  entity_id
  id
  producing_run_id
  owner_user_id
  collection_id
}

input GenomicRangeCreateInput {
  producingRunId: ID = null
  collectionId: Int!
  referenceGenomeId: ID!
  fileId: ID = null
}

"""An edge in a connection."""
type GenomicRangeEdge {
  """A cursor for use in pagination"""
  cursor: String!
  """The item at the end of the edge"""
  node: GenomicRange!
}

type GenomicRangeMinMaxColumns {
  producingRunId: Int
  ownerUserId: Int
  collectionId: Int
}

type GenomicRangeNumericalColumns {
  producingRunId: Int
  ownerUserId: Int
  collectionId: Int
  ownerUserId: Int
  producingRunId: Int
}

input GenomicRangeUpdateInput {
  collectionId: Int = null
  referenceGenomeId: ID = null
  fileId: ID = null
}

input GenomicRangeWhereClause {
  id: UUIDComparators
  producingRunId: IntComparators
  ownerUserId: IntComparators
  collectionId: IntComparators
  referenceGenome: ReferenceGenomeWhereClause
  sequencingReads: SequencingReadWhereClause
}

input GenomicRangeWhereClauseMutations {
  id: UUIDComparators
}

"""
The \`ID\` scalar type represents a unique identifier, often used to refetch an object or as key for a cache. The ID type appears in a JSON response as a String; however, it is not intended to be human-readable. When expected as an input type, any string (such as \`"4"\`) or integer (such as \`4\`) input value will be accepted as an ID.
"""
scalar GlobalID @specifiedBy(url: "https://relay.dev/graphql/objectidentification.htm")

input IntComparators {
  _eq: Int
  _gt: Int
  _gte: Int
  _in: [Int!]
  _is_null: Int
  _lt: Int
  _lte: Int
  _neq: Int
  _nin: [Int!]
}

"""
The \`JSON\` scalar type represents JSON values as specified by [ECMA-404](http://www.ecma-international.org/publications/files/ECMA-ST/ECMA-404.pdf).
"""
scalar JSON @specifiedBy(url: "http://www.ecma-international.org/publications/files/ECMA-ST/ECMA-404.pdf")

type MetadataField implements EntityInterface & Node {
  """The Globally Unique ID of this object"""
  _id: GlobalID!
  collectionId: Int!
  defaultValue: String
  description: String!
  fieldGroup(
    """Returns the items in the list that come after the specified cursor."""
    after: String = null
    """Returns the items in the list that come before the specified cursor."""
    before: String = null
    """Returns the first n items from the list."""
    first: Int = null
    """Returns the items in the list that come after the specified cursor."""
    last: Int = null
    where: MetadataFieldProjectWhereClause = null
  ): MetadataFieldProjectConnection!
  fieldGroupAggregate(where: MetadataFieldProjectWhereClause = null): MetadataFieldProjectAggregate
  fieldName: String!
  fieldType: String!
  id: ID!
  producingRunId: Int
  ownerUserId: Int!
  collectionId: Int!
  sample(where: SampleWhereClause = null): Sample
  fieldName: String!
  value: String!
  producingRunId: ID
  ownerUserId: Int!
  collectionId: Int!
  createdAt: DateTime!
  updatedAt: DateTime
}

type MetadatumAggregate {
  aggregate: [MetadatumAggregateFunctions!]
}

type MetadatumAggregateFunctions {
  avg: MetadatumNumericalColumns
  min: MetadatumMinMaxColumns
  max: MetadatumMinMaxColumns
  stddev: MetadatumNumericalColumns
  sum: MetadatumNumericalColumns
  variance: MetadatumNumericalColumns
  count(distinct: Boolean = false, columns: MetadatumCountColumns = null): Int
}

"""A connection to a list of items."""
type MetadatumConnection {
  """Contains the nodes in this connection"""
  edges: [MetadatumEdge!]!
  """Pagination data for this connection"""
  pageInfo: PageInfo!
}

enum MetadatumCountColumns {
  sample
  field_name
  value
  entity_id
  id
  producing_run_id
  owner_user_id
  collection_id
}

input MetadatumCreateInput {
  collectionId: Int!
  sampleId: ID!
  value: String!
  producingRunId: ID = null
  collectionId: Int!
}

"""An edge in a connection."""
type MetadatumEdge {
  """A cursor for use in pagination"""
  cursor: String!
  """The item at the end of the edge"""
  node: Metadatum!
}

type MetadatumMinMaxColumns {
  producingRunId: Int
  ownerUserId: Int
  collectionId: Int
  fieldName: String
  value: String
  ownerUserId: Int
  collectionId: Int
  createdAt: DateTime
  updatedAt: DateTime
}

type MetadatumNumericalColumns {
  producingRunId: Int
  ownerUserId: Int
  collectionId: Int
  ownerUserId: Int
  producingRunId: Int
}

input MetadatumOrderByClause {
  sample: SampleOrderByClause
  fieldName: orderBy
  value: orderBy
  id: orderBy
  producingRunId: orderBy
  ownerUserId: orderBy
  collectionId: orderBy
  createdAt: orderBy
  updatedAt: orderBy
}

input MetadatumUpdateInput {
  collectionId: Int = null
  sampleId: ID = null
  fieldName: String = null
  value: String = null
}

input MetadatumWhereClause {
  id: UUIDComparators
  producingRunId: IntComparators
  ownerUserId: IntComparators
  collectionId: IntComparators
  sample: SampleWhereClause
  value: StrComparators
  id: UUIDComparators
  producingRunId: UUIDComparators
  ownerUserId: IntComparators
  collectionId: IntComparators
  createdAt: DatetimeComparators
  updatedAt: DatetimeComparators
}

input MetadatumWhereClauseMutations {
  id: UUIDComparators
}

type MetricConsensusGenome implements EntityInterface & Node {
  """The Globally Unique ID of this object"""
  _id: GlobalID!
  id: ID!
  producingRunId: Int
  ownerUserId: Int!
  collectionId: Int!
  consensusGenome(where: ConsensusGenomeWhereClause = null): ConsensusGenome
  coverageDepth: Float
  referenceGenomeLength: Float
  percentGenomeCalled: Float
  percentIdentity: Float
  gcPercent: Float
  id: ID!
  mappedReads: Int
  nActg: Int
  nAmbiguous: Int
  coverageVizSummaryFileId: ID
  coverageVizSummaryFile(where: FileWhereClause = null): File
}

type MetricConsensusGenomeAggregate {
  aggregate: [MetricConsensusGenomeAggregateFunctions!]
}

type MetricConsensusGenomeAggregateFunctions {
  avg: MetricConsensusGenomeNumericalColumns
  min: MetricConsensusGenomeMinMaxColumns
  max: MetricConsensusGenomeMinMaxColumns
  stddev: MetricConsensusGenomeNumericalColumns
  sum: MetricConsensusGenomeNumericalColumns
  variance: MetricConsensusGenomeNumericalColumns
  count(distinct: Boolean = false, columns: MetricConsensusGenomeCountColumns = null): Int
}

"""A connection to a list of items."""
type MetricConsensusGenomeConnection {
  """Pagination data for this connection"""
  pageInfo: PageInfo!
  """Contains the nodes in this connection"""
  edges: [MetricConsensusGenomeEdge!]!
}

enum MetricConsensusGenomeCountColumns {
  consensus_genome
  coverage_depth
  reference_genome_length
  percent_genome_called
  percent_identity
  gc_percent
  total_reads
  mapped_reads
  ref_snps
  n_actg
  n_missing
  n_ambiguous
  coverage_viz_summary_file
  entity_id
  id
  producing_run_id
  owner_user_id
  collection_id
}

input MetricConsensusGenomeCreateInput {
  consensusGenomeId: ID!
  coverageDepth: Float = null
  referenceGenomeLength: Float = null
  percentGenomeCalled: Float = null
  percentIdentity: Float = null
  gcPercent: Float = null
  mappedReads: Int = null
  nActg: Int = null
  nAmbiguous: Int = null
  coverageVizSummaryFileId: ID = null
}

"""An edge in a connection."""
type MetricConsensusGenomeEdge {
  """A cursor for use in pagination"""
  cursor: String!
  """The item at the end of the edge"""
  node: MetricConsensusGenome!
}

type MetricConsensusGenomeMinMaxColumns {
  producingRunId: Int
  ownerUserId: Int
  collectionId: Int
  coverageDepth: Float
  referenceGenomeLength: Float
  percentGenomeCalled: Float
  percentIdentity: Float
  gcPercent: Float
  mappedReads: Int
  nActg: Int
  nAmbiguous: Int
}

type MetricConsensusGenomeNumericalColumns {
  producingRunId: Int
  ownerUserId: Int
  collectionId: Int
  coverageDepth: Float
  referenceGenomeLength: Float
  percentGenomeCalled: Float
  percentIdentity: Float
  gcPercent: Float
  mappedReads: Int
  nActg: Int
  nAmbiguous: Int
}

input MetricConsensusGenomeUpdateInput {
  collectionId: Int = null
  consensusGenomeId: ID = null
  coverageDepth: Float = null
  referenceGenomeLength: Float = null
  percentGenomeCalled: Float = null
  percentIdentity: Float = null
  gcPercent: Float = null
  totalReads: Int = null
  mappedReads: Int = null
  refSnps: Int = null
  nActg: Int = null
  nMissing: Int = null
  nAmbiguous: Int = null
  coverageVizSummaryFileId: ID = null
}

input MetricConsensusGenomeWhereClause {
  id: UUIDComparators
  producingRunId: IntComparators
  ownerUserId: IntComparators
  collectionId: IntComparators
  consensusGenome: ConsensusGenomeWhereClause
  coverageDepth: FloatComparators
  referenceGenomeLength: FloatComparators
  percentGenomeCalled: FloatComparators
  percentIdentity: FloatComparators
  gcPercent: FloatComparators
  id: UUIDComparators
  mappedReads: IntComparators
  nActg: IntComparators
  nAmbiguous: IntComparators
}

input MetricConsensusGenomeWhereClauseMutations {
  id: UUIDComparators
}

type MngsRunInfo {
  createdAt: ISO8601DateTime
  finalized: Int
  reportReady: Boolean
  resultStatusDescription: String
  totalRuntime: Int
  withAssembly: Int
}

type MngsWorkflowResults {
  _: query_MngsWorkflowResults__
  metric_mngs: query_MngsWorkflowResults_metric_mngs
  taxon_hit_results: query_MngsWorkflowResults_taxon_hit_results
}

type MultipartUploadCredentials {
  accessKeyId: String!
  expiration: String!
  namespace: String!
  path: String!
  protocol: String!
  secretAccessKey: String!
  sessionToken: String!
}

type MultipartUploadResponse {
  credentials: MultipartUploadCredentials!
  file: File!
}

type Mutation {
  CreateBulkDownload(input: mutationInput_CreateBulkDownload_input_Input): JSON @httpOperation(path: "/bulk_download", httpMethod: POST)
  DeleteSamples(input: mutationInput_DeleteSamples_input_Input): DeleteSamples @httpOperation(path: "/samples/bulk_delete", httpMethod: POST)
  KickoffAMRWorkflow(input: mutationInput_KickoffAMRWorkflow_input_Input, sampleId: String): [mutation_KickoffWGSWorkflow_items] @httpOperation(path: "/samples/{args.sampleId}/kickoff_workflow", operationSpecificHeaders: "{\\"Cookie\\":\\"{context.headers['cookie']}\\"}", httpMethod: POST)
  KickoffWGSWorkflow(input: mutationInput_KickoffWGSWorkflow_input_Input, sampleId: String): [mutation_KickoffWGSWorkflow_items] @httpOperation(path: "/samples/{args.sampleId}/kickoff_workflow", operationSpecificHeaders: "{\\"Cookie\\":\\"{context.headers['cookie']}\\"}", httpMethod: POST)
  UpdateMetadata(input: mutationInput_UpdateMetadata_input_Input, sampleId: String): UpdateMetadataReponse @httpOperation(path: "/samples/{args.sampleId}/save_metadata_v2", operationSpecificHeaders: "{\\"Cookie\\":\\"{context.headers['cookie']}\\"}", httpMethod: POST)
  UpdateSampleName(input: mutationInput_UpdateSampleNotes_input_Input, sampleId: String): UpdateSampleName @httpOperation(path: "/samples/{args.sampleId}/save_metadata", operationSpecificHeaders: "{\\"Cookie\\":\\"{context.headers['cookie']}\\"}", httpMethod: POST)
  UpdateSampleNotes(input: mutationInput_UpdateSampleNotes_input_Input, sampleId: String): UpdateSampleNotes @httpOperation(path: "/samples/{args.sampleId}/save_metadata", operationSpecificHeaders: "{\\"Cookie\\":\\"{context.headers['cookie']}\\"}", httpMethod: POST)
  concatenateFiles(ids: [UUID!]!): SignedURL!
  createConsensusGenome(input: ConsensusGenomeCreateInput!): ConsensusGenome!
  createContig(input: ContigCreateInput!): Contig!
  createFile(entityFieldName: String!, entityId: ID!, file: FileCreate!): File!
  createGenomicRange(input: GenomicRangeCreateInput!): GenomicRange!
  createMetadataField(input: MetadataFieldCreateInput!): MetadataField!
  createMetadataFieldProject(input: MetadataFieldProjectCreateInput!): MetadataFieldProject!
  createMetadatum(input: MetadatumCreateInput!): Metadatum!
  createMetricConsensusGenome(input: MetricConsensusGenomeCreateInput!): MetricConsensusGenome!
  createPhylogeneticTree(input: PhylogeneticTreeCreateInput!): PhylogeneticTree!
  createReferenceGenome(input: ReferenceGenomeCreateInput!): ReferenceGenome!
  createRun(input: RunCreateInput!): Run!
  createRunEntityInput(input: RunEntityInputCreateInput!): RunEntityInput!
  createRunStep(input: RunStepCreateInput!): RunStep!
  createSample(input: SampleCreateInput!): Sample!
  createSequenceAlignmentIndex(input: SequenceAlignmentIndexCreateInput!): SequenceAlignmentIndex!
  createSequencingRead(input: SequencingReadCreateInput!): SequencingRead!
  createTaxon(input: TaxonCreateInput!): Taxon!
  createUpstreamDatabase(input: UpstreamDatabaseCreateInput!): UpstreamDatabase!
  createUser(archetypes: String, email: String!, institution: String, name: String, role: Int, segments: String, sendActivation: Boolean): CreateUserPayload!
  createWorkflow(input: WorkflowCreateInput!): Workflow!
  createWorkflowVersion(input: WorkflowVersionCreateInput!): WorkflowVersion!
  deleteConsensusGenome(where: ConsensusGenomeWhereClauseMutations!): [ConsensusGenome!]!
  deleteContig(where: ContigWhereClauseMutations!): [Contig!]!
  deleteGenomicRange(where: GenomicRangeWhereClauseMutations!): [GenomicRange!]!
  deleteMetadataField(where: MetadataFieldWhereClauseMutations!): [MetadataField!]!
  deleteMetadataFieldProject(where: MetadataFieldProjectWhereClauseMutations!): [MetadataFieldProject!]!
  deleteMetadatum(where: MetadatumWhereClauseMutations!): [Metadatum!]!
  deleteMetricConsensusGenome(where: MetricConsensusGenomeWhereClauseMutations!): [MetricConsensusGenome!]!
  deletePhylogeneticTree(where: PhylogeneticTreeWhereClauseMutations!): [PhylogeneticTree!]!
  deleteReferenceGenome(where: ReferenceGenomeWhereClauseMutations!): [ReferenceGenome!]!
  deleteRun(where: RunWhereClauseMutations!): [Run!]!
  deleteRunEntityInput(where: RunEntityInputWhereClauseMutations!): [RunEntityInput!]!
  deleteRunStep(where: RunStepWhereClauseMutations!): [RunStep!]!
  deleteSample(where: SampleWhereClauseMutations!): [Sample!]!
  deleteSequenceAlignmentIndex(where: SequenceAlignmentIndexWhereClauseMutations!): [SequenceAlignmentIndex!]!
  deleteSequencingRead(where: SequencingReadWhereClauseMutations!): [SequencingRead!]!
  deleteTaxon(where: TaxonWhereClauseMutations!): [Taxon!]!
  deleteUpstreamDatabase(where: UpstreamDatabaseWhereClauseMutations!): [UpstreamDatabase!]!
  deleteWorkflow(where: WorkflowWhereClauseMutations!): [Workflow!]!
  deleteWorkflowVersion(where: WorkflowVersionWhereClauseMutations!): [WorkflowVersion!]!
  markUploadComplete(fileId: ID!): File!
  updateConsensusGenome(input: ConsensusGenomeUpdateInput!, where: ConsensusGenomeWhereClauseMutations!): [ConsensusGenome!]!
  updateContig(input: ContigUpdateInput!, where: ContigWhereClauseMutations!): [Contig!]!
  updateGenomicRange(input: GenomicRangeUpdateInput!, where: GenomicRangeWhereClauseMutations!): [GenomicRange!]!
  updateMetadataField(input: MetadataFieldUpdateInput!, where: MetadataFieldWhereClauseMutations!): [MetadataField!]!
  updateMetadataFieldProject(input: MetadataFieldProjectUpdateInput!, where: MetadataFieldProjectWhereClauseMutations!): [MetadataFieldProject!]!
  updateMetadatum(input: MetadatumUpdateInput!, where: MetadatumWhereClauseMutations!): [Metadatum!]!
  updateMetricConsensusGenome(input: MetricConsensusGenomeUpdateInput!, where: MetricConsensusGenomeWhereClauseMutations!): [MetricConsensusGenome!]!
  updatePhylogeneticTree(input: PhylogeneticTreeUpdateInput!, where: PhylogeneticTreeWhereClauseMutations!): [PhylogeneticTree!]!
  updateReferenceGenome(input: ReferenceGenomeUpdateInput!, where: ReferenceGenomeWhereClauseMutations!): [ReferenceGenome!]!
  updateRun(input: RunUpdateInput!, where: RunWhereClauseMutations!): [Run!]!
  updateRunEntityInput(input: RunEntityInputUpdateInput!, where: RunEntityInputWhereClauseMutations!): [RunEntityInput!]!
  updateRunStep(input: RunStepUpdateInput!, where: RunStepWhereClauseMutations!): [RunStep!]!
  updateSample(input: SampleUpdateInput!, where: SampleWhereClauseMutations!): [Sample!]!
  updateSequenceAlignmentIndex(input: SequenceAlignmentIndexUpdateInput!, where: SequenceAlignmentIndexWhereClauseMutations!): [SequenceAlignmentIndex!]!
  updateSequencingRead(input: SequencingReadUpdateInput!, where: SequencingReadWhereClauseMutations!): [SequencingRead!]!
  updateTaxon(input: TaxonUpdateInput!, where: TaxonWhereClauseMutations!): [Taxon!]!
  updateUpstreamDatabase(input: UpstreamDatabaseUpdateInput!, where: UpstreamDatabaseWhereClauseMutations!): [UpstreamDatabase!]!
  updateWorkflow(input: WorkflowUpdateInput!, where: WorkflowWhereClauseMutations!): [Workflow!]!
  updateWorkflowVersion(input: WorkflowVersionUpdateInput!, where: WorkflowVersionWhereClauseMutations!): [WorkflowVersion!]!
  uploadFile(entityFieldName: String!, entityId: ID!, expiration: Int! = 3600, file: FileUpload!): MultipartUploadResponse!
}

"""An object with a Globally Unique ID"""
interface Node {
  """The Globally Unique ID of this object"""
  _id: GlobalID!
}

enum NucleicAcid {
  RNA
  DNA
}

input NucleicAcidEnumComparators {
  _eq: NucleicAcid
  _neq: NucleicAcid
  _in: [NucleicAcid!]
  _nin: [NucleicAcid!]
  _gt: NucleicAcid
  _gte: NucleicAcid
  _lt: NucleicAcid
  _lte: NucleicAcid
  _is_null: NucleicAcid
}

"""Information to aid in pagination."""
type PageInfo {
  """When paginating forwards, the cursor to continue."""
  endCursor: String
  """When paginating forwards, are there more items?"""
  hasNextPage: Boolean!
  """When paginating backwards, are there more items?"""
  hasPreviousPage: Boolean!
  """When paginating backwards, the cursor to continue."""
  startCursor: String
}

type Pathogen {
  category: String
  name: String
  taxId: Int
}

type PathogenList {
  citations: [String!]
  createdAt: ISO8601DateTime
  id: ID
  name: String
  pathogens: [Pathogen!]
  updatedAt: ISO8601DateTime
  version: String
}

type PersistedBackground {
  background_id: Int
}

type PhylogeneticTree implements EntityInterface & Node {
  """The Globally Unique ID of this object"""
  _id: GlobalID!
  id: ID!
  producingRunId: Int
  ownerUserId: Int!
  collectionId: Int!
  treeId: ID
  tree(where: FileWhereClause = null): File
  format: PhylogeneticTreeFormat!
}

type PhylogeneticTreeAggregate {
  aggregate: PhylogeneticTreeAggregateFunctions
}

type PhylogeneticTreeAggregateFunctions {
  sum: PhylogeneticTreeNumericalColumns
  avg: PhylogeneticTreeNumericalColumns
  min: PhylogeneticTreeMinMaxColumns
  max: PhylogeneticTreeMinMaxColumns
  stddev: PhylogeneticTreeNumericalColumns
  variance: PhylogeneticTreeNumericalColumns
  count(distinct: Boolean = false, columns: PhylogeneticTreeCountColumns = null): Int
}

enum PhylogeneticTreeCountColumns {
  tree
  format
  entity_id
  id
  producing_run_id
  owner_user_id
  collection_id
}

input PhylogeneticTreeCreateInput {
  collectionId: Int!
  treeId: ID = null
  format: PhylogeneticTreeFormat!
}

enum PhylogeneticTreeFormat {
  newick
  auspice_v1
  auspice_v2
}

input PhylogeneticTreeFormatEnumComparators {
  _eq: PhylogeneticTreeFormat
  _neq: PhylogeneticTreeFormat
  _in: [PhylogeneticTreeFormat!]
  _nin: [PhylogeneticTreeFormat!]
  _gt: PhylogeneticTreeFormat
  _gte: PhylogeneticTreeFormat
  _lt: PhylogeneticTreeFormat
  _lte: PhylogeneticTreeFormat
  _is_null: PhylogeneticTreeFormat
}

type PhylogeneticTreeMinMaxColumns {
  producingRunId: Int
  ownerUserId: Int
  collectionId: Int
}

type PhylogeneticTreeNumericalColumns {
  producingRunId: Int
  ownerUserId: Int
  collectionId: Int
}

input PhylogeneticTreeUpdateInput {
  collectionId: Int = null
  treeId: ID = null
  format: PhylogeneticTreeFormat = null
}

input PhylogeneticTreeWhereClause {
  id: UUIDComparators
  producingRunId: IntComparators
  ownerUserId: IntComparators
  collectionId: IntComparators
  format: PhylogeneticTreeFormatEnumComparators
}

input PhylogeneticTreeWhereClauseMutations {
  id: UUIDComparators
}

type ReferenceGenome implements EntityInterface & Node {
  """The Globally Unique ID of this object"""
  _id: GlobalID!
  id: ID!
  producingRunId: Int
  ownerUserId: Int!
  collectionId: Int!
  fileId: ID
  file(where: FileWhereClause = null): File
  fileIndexId: ID
  fileIndex(where: FileWhereClause = null): File
  name: String!
  description: String!
  taxon(where: TaxonWhereClause = null): Taxon
  accessionId: String
  sequenceAlignmentIndices(
    where: SequenceAlignmentIndexWhereClause = null
    """Returns the items in the list that come before the specified cursor."""
    before: String = null
    """Returns the items in the list that come after the specified cursor."""
    after: String = null
    """Returns the first n items from the list."""
    first: Int = null
    """Returns the items in the list that come after the specified cursor."""
    last: Int = null
  ): SequenceAlignmentIndexConnection!
  sequenceAlignmentIndicesAggregate(where: SequenceAlignmentIndexWhereClause = null): SequenceAlignmentIndexAggregate
  consensusGenomes(
    where: ConsensusGenomeWhereClause = null
    """Returns the items in the list that come before the specified cursor."""
    before: String = null
    """Returns the items in the list that come after the specified cursor."""
    after: String = null
    """Returns the items in the list that come before the specified cursor."""
    before: String = null
    """Returns the first n items from the list."""
    first: Int = null
    """Returns the items in the list that come after the specified cursor."""
    last: Int = null
  ): ConsensusGenomeConnection!
  consensusGenomesAggregate(where: ConsensusGenomeWhereClause = null): ConsensusGenomeAggregate
  genomicRanges(
    where: GenomicRangeWhereClause = null
    """Returns the items in the list that come before the specified cursor."""
    before: String = null
    """Returns the items in the list that come after the specified cursor."""
    after: String = null
    """Returns the first n items from the list."""
    first: Int = null
    """Returns the items in the list that come after the specified cursor."""
    last: Int = null
  ): GenomicRangeConnection!
  genomicRangesAggregate(where: GenomicRangeWhereClause = null): GenomicRangeAggregate
}

type ReferenceGenomeAggregate {
  aggregate: [ReferenceGenomeAggregateFunctions!]
}

type ReferenceGenomeAggregateFunctions {
  avg: ReferenceGenomeNumericalColumns
  min: ReferenceGenomeMinMaxColumns
  max: ReferenceGenomeMinMaxColumns
  stddev: ReferenceGenomeNumericalColumns
  sum: ReferenceGenomeNumericalColumns
  variance: ReferenceGenomeNumericalColumns
  count(distinct: Boolean = false, columns: ReferenceGenomeCountColumns = null): Int
}

"""A connection to a list of items."""
type ReferenceGenomeConnection {
  """Pagination data for this connection"""
  pageInfo: PageInfo!
  """Contains the nodes in this connection"""
  edges: [ReferenceGenomeEdge!]!
}

enum ReferenceGenomeCountColumns {
  file
  file_index
  name
  description
  taxon
  accession_id
  sequence_alignment_indices
  consensus_genomes
  genomic_ranges
  entity_id
  id
  producing_run_id
  owner_user_id
  collection_id
}

input ReferenceGenomeCreateInput {
  collectionId: Int!
  fileId: ID = null
  fileIndexId: ID = null
  name: String!
  description: String!
  taxonId: ID!
  accessionId: String = null
}

"""An edge in a connection."""
type ReferenceGenomeEdge {
  """A cursor for use in pagination"""
  cursor: String!
  """The item at the end of the edge"""
  node: ReferenceGenome!
}

type ReferenceGenomeMinMaxColumns {
  producingRunId: Int
  ownerUserId: Int
  collectionId: Int
  name: String
  description: String
  accessionId: String
}

type ReferenceGenomeNumericalColumns {
  producingRunId: Int
  ownerUserId: Int
  collectionId: Int
  ownerUserId: Int
  producingRunId: Int
}

input ReferenceGenomeOrderByClause {
  name: orderBy
  id: orderBy
  producingRunId: orderBy
  ownerUserId: orderBy
  collectionId: orderBy
  createdAt: orderBy
  updatedAt: orderBy
}

input ReferenceGenomeUpdateInput {
  collectionId: Int = null
  fileId: ID = null
  fileIndexId: ID = null
  name: String = null
  description: String = null
  taxonId: ID = null
  accessionId: String = null
}

input ReferenceGenomeWhereClause {
  id: UUIDComparators
  producingRunId: IntComparators
  ownerUserId: IntComparators
  collectionId: IntComparators
  name: StrComparators
  description: StrComparators
  taxon: TaxonWhereClause
  accessionId: StrComparators
  sequenceAlignmentIndices: SequenceAlignmentIndexWhereClause
  consensusGenomes: ConsensusGenomeWhereClause
  genomicRanges: GenomicRangeWhereClause
}

input ReferenceGenomeWhereClauseMutations {
  id: UUIDComparators
}

type Sample implements EntityInterface & Node {
  """The Globally Unique ID of this object"""
  _id: GlobalID!
  id: ID!
  producingRunId: Int
  ownerUserId: Int!
  collectionId: Int!
  name: String!
  sampleType: String!
  waterControl: Boolean!
  collectionDate: DateTime
  collectionLocation: String!
  description: String
  hostTaxon(where: TaxonWhereClause = null): Taxon
  sequencingReads(
    where: SequencingReadWhereClause = null
    """Returns the items in the list that come before the specified cursor."""
    before: String = null
    """Returns the items in the list that come after the specified cursor."""
    after: String = null
    """Returns the first n items from the list."""
    first: Int = null
    """Returns the items in the list that come after the specified cursor."""
    last: Int = null
  ): SequencingReadConnection!
  sequencingReadsAggregate(where: SequencingReadWhereClause = null): SequencingReadAggregate
  metadatas(
    where: MetadatumWhereClause = null
    """Returns the items in the list that come before the specified cursor."""
    before: String = null
    """Returns the items in the list that come after the specified cursor."""
    after: String = null
    """Returns the first n items from the list."""
    first: Int = null
    """Returns the items in the list that come after the specified cursor."""
    last: Int = null
  ): MetadatumConnection!
  metadatasAggregate(where: MetadatumWhereClause = null): MetadatumAggregate
  alignmentConfigName: String
  basespaceAccessToken: String
  createdAt: ISO8601DateTime
  dagVars: String
  defaultBackgroundId: Int
  defaultPipelineRunId: Int
  details: SampleDetails!
  doNotProcess: Boolean!
  editable: Boolean
  hostGenome: HostGenome
  hostGenomeId: Int
  initialWorkflow: String!
  maxInputFragments: Int
  pipelineBranch: String
  pipelineCommit: String
  pipelineExecutionStrategy: String
  pipelineRuns: [PipelineRun!]
  privateUntil: ISO8601DateTime
  project: Project
  projectId: Int
  public: Int!
  s3Bowtie2IndexPath: String
  s3PreloadResultPath: String
  s3StarIndexPath: String
  sampleDeletable: Boolean
  sampleNotes: String
  status: String
  subsample: Int
  updatedAt: ISO8601DateTime
  uploadError: String
  uploadedFromBasespace: Int
  useTaxonWhitelist: Boolean!
  user: User
  userId: Int
  webCommit: String
  workflowRuns: [WorkflowRun!]
}

type SampleAggregate {
  aggregate: [SampleAggregateFunctions!]
}

type SampleAggregateFunctions {
  avg: SampleNumericalColumns
  min: SampleMinMaxColumns
  max: SampleMinMaxColumns
  stddev: SampleNumericalColumns
  sum: SampleNumericalColumns
  variance: SampleNumericalColumns
  count(distinct: Boolean = false, columns: SampleCountColumns = null): Int
}

"""A connection to a list of items."""
type SampleConnection {
  """Contains the nodes in this connection"""
  edges: [SampleEdge!]!
  """Pagination data for this connection"""
  pageInfo: PageInfo!
}

enum SampleCountColumns {
  name
  sample_type
  water_control
  collection_date
  collection_location
  description
  host_taxon
  sequencing_reads
  metadatas
  entity_id
  id
  producing_run_id
  owner_user_id
  collection_id
}

input SampleCreateInput {
  collectionId: Int!
  name: String!
  sampleType: String!
  waterControl: Boolean!
  collectionDate: DateTime = null
  collectionLocation: String!
  description: String = null
  hostTaxonId: ID = null
}

"""An edge in a connection."""
type SampleEdge {
  """A cursor for use in pagination"""
  cursor: String!
  """The item at the end of the edge"""
  node: Sample!
}

type SampleMinMaxColumns {
  producingRunId: Int
  ownerUserId: Int
  collectionId: Int
  name: String
  sampleType: String
  collectionDate: DateTime
  collectionLocation: String
  description: String
}

type SampleNumericalColumns {
  producingRunId: Int
  ownerUserId: Int
  collectionId: Int
  ownerUserId: Int
  producingRunId: Int
}

type SampleReadsStats {
  initialReads: Int
  name: String
  pipelineVersion: String
  sampleId: ID!
  steps: [SampleSteps!]
  wdlVersion: String
}

type SampleReadsStatsList {
  sampleReadsStats: [SampleReadsStats!]!
}

type SampleSteps {
  name: String
  readsAfter: Int
}

type SampleSummaryStats {
  adjustedRemainingReads: Int
  compressionRatio: Float
  insertSizeMean: Float
  insertSizeStandardDeviation: Float
  lastProcessedAt: ISO8601DateTime
  percentRemaining: Float
  qcPercent: Float
  readsAfterCzidDedup: Int
  readsAfterPriceseq: Int
  readsAfterStar: Int
  readsAfterTrimmomatic: Int
  unmappedReads: Int
}

input SampleOrderByClause {
  railsSampleId: orderBy
  name: orderBy
  hostOrganism: HostOrganismOrderByClause
  id: orderBy
  producingRunId: orderBy
  ownerUserId: orderBy
  collectionId: orderBy
  createdAt: orderBy
  updatedAt: orderBy
}

input SampleUpdateInput {
  collectionId: Int = null
  name: String = null
  sampleType: String = null
  waterControl: Boolean = null
  collectionDate: DateTime = null
  collectionLocation: String = null
  description: String = null
  hostTaxonId: ID = null
}

input SampleWhereClause {
  id: UUIDComparators
  producingRunId: IntComparators
  ownerUserId: IntComparators
  collectionId: IntComparators
  name: StrComparators
  sampleType: StrComparators
  waterControl: BoolComparators
  collectionDate: DatetimeComparators
  collectionLocation: StrComparators
  description: StrComparators
  hostTaxon: TaxonWhereClause
  sequencingReads: SequencingReadWhereClause
  metadatas: MetadatumWhereClause
}

input SampleWhereClauseMutations {
  id: UUIDComparators
}

type SequenceAlignmentIndex implements EntityInterface & Node {
  """The Globally Unique ID of this object"""
  _id: GlobalID!
  id: ID!
  producingRunId: Int
  ownerUserId: Int!
  collectionId: Int!
  indexFileId: ID
  indexFile(where: FileWhereClause = null): File
  referenceGenome(where: ReferenceGenomeWhereClause = null): ReferenceGenome
  tool: AlignmentTool!
  version: String
}

type SequenceAlignmentIndexAggregate {
  aggregate: SequenceAlignmentIndexAggregateFunctions
}

type SequenceAlignmentIndexAggregateFunctions {
  sum: SequenceAlignmentIndexNumericalColumns
  avg: SequenceAlignmentIndexNumericalColumns
  min: SequenceAlignmentIndexMinMaxColumns
  max: SequenceAlignmentIndexMinMaxColumns
  stddev: SequenceAlignmentIndexNumericalColumns
  variance: SequenceAlignmentIndexNumericalColumns
  count(distinct: Boolean = false, columns: SequenceAlignmentIndexCountColumns = null): Int
}

"""A connection to a list of items."""
type SequenceAlignmentIndexConnection {
  """Pagination data for this connection"""
  pageInfo: PageInfo!
  """Contains the nodes in this connection"""
  edges: [SequenceAlignmentIndexEdge!]!
}

enum SequenceAlignmentIndexCountColumns {
  index_file
  reference_genome
  tool
  version
  entity_id
  id
  producing_run_id
  owner_user_id
  collection_id
}

input SequenceAlignmentIndexCreateInput {
  collectionId: Int!
  indexFileId: ID = null
  referenceGenomeId: ID = null
  tool: AlignmentTool!
  version: String = null
}

"""An edge in a connection."""
type SequenceAlignmentIndexEdge {
  """A cursor for use in pagination"""
  cursor: String!
  """The item at the end of the edge"""
  node: SequenceAlignmentIndex!
}

type SequenceAlignmentIndexMinMaxColumns {
  producingRunId: Int
  ownerUserId: Int
  collectionId: Int
  version: String
}

type SequenceAlignmentIndexNumericalColumns {
  producingRunId: Int
  ownerUserId: Int
  collectionId: Int
}

input SequenceAlignmentIndexUpdateInput {
  collectionId: Int = null
  indexFileId: ID = null
  referenceGenomeId: ID = null
  tool: AlignmentTool = null
  version: String = null
}

input SequenceAlignmentIndexWhereClause {
  id: UUIDComparators
  producingRunId: IntComparators
  ownerUserId: IntComparators
  collectionId: IntComparators
  referenceGenome: ReferenceGenomeWhereClause
  tool: AlignmentToolEnumComparators
  version: StrComparators
}

input SampleWhereClauseMutations {
  id: UUIDComparators
}

enum SequencingProtocol {
  ampliseq
  artic
  artic_v3
  artic_v4
  artic_v5
  combined_msspe_artic
  covidseq
  easyseq
  midnight
  msspe
  snap
  varskip
}

input SequencingProtocolEnumComparators {
  _eq: SequencingProtocol
  _gt: SequencingProtocol
  _gte: SequencingProtocol
  _in: [SequencingProtocol!]
  _is_null: SequencingProtocol
  _lt: SequencingProtocol
  _lte: SequencingProtocol
  _neq: SequencingProtocol
  _nin: [SequencingProtocol!]
}

type SequencingRead implements EntityInterface & Node {
  """The Globally Unique ID of this object"""
  _id: GlobalID!
  id: ID!
  producingRunId: Int
  ownerUserId: Int!
  collectionId: Int!
  sample(where: SampleWhereClause = null): Sample
  protocol: SequencingProtocol!
  r1FileId: ID
  r1File(where: FileWhereClause = null): File
  r2FileId: ID
  r2File(where: FileWhereClause = null): File
  technology: SequencingTechnology!
  nucleicAcid: NucleicAcid!
  hasErcc: Boolean!
  taxon(where: TaxonWhereClause = null): Taxon
  primerFile(where: GenomicRangeWhereClause = null): GenomicRange
  consensusGenomes(
    where: ConsensusGenomeWhereClause = null
    """Returns the items in the list that come before the specified cursor."""
    before: String = null
    """Returns the items in the list that come after the specified cursor."""
    after: String = null
    """Returns the items in the list that come before the specified cursor."""
    before: String = null
    """Returns the first n items from the list."""
    first: Int = null
    """Returns the items in the list that come after the specified cursor."""
    last: Int = null
    where: ConsensusGenomeWhereClause = null
  ): ConsensusGenomeConnection!
  consensusGenomesAggregate(where: ConsensusGenomeWhereClause = null): ConsensusGenomeAggregate
  contigs(
    where: ContigWhereClause = null
    """Returns the items in the list that come before the specified cursor."""
    before: String = null
    """Returns the items in the list that come after the specified cursor."""
    after: String = null
    """Returns the first n items from the list."""
    first: Int = null
    """Returns the items in the list that come after the specified cursor."""
    last: Int = null
  ): ContigConnection!
  contigsAggregate(where: ContigWhereClause = null): ContigAggregate
}

type SequencingReadAggregate {
  aggregate: [SequencingReadAggregateFunctions!]
}

type SequencingReadAggregateFunctions {
  avg: SequencingReadNumericalColumns
  min: SequencingReadMinMaxColumns
  max: SequencingReadMinMaxColumns
  stddev: SequencingReadNumericalColumns
  sum: SequencingReadNumericalColumns
  variance: SequencingReadNumericalColumns
  count(distinct: Boolean = false, columns: SequencingReadCountColumns = null): Int
}

"""A connection to a list of items."""
type SequencingReadConnection {
  """Contains the nodes in this connection"""
  edges: [SequencingReadEdge!]!
  """Pagination data for this connection"""
  pageInfo: PageInfo!
}

enum SequencingReadCountColumns {
  sample
  protocol
  r1_file
  r2_file
  technology
  nucleic_acid
  has_ercc
  taxon
  primer_file
  consensus_genomes
  contigs
  entity_id
  id
  producing_run_id
  owner_user_id
  collection_id
}

input SequencingReadCreateInput {
  collectionId: Int!
  sampleId: ID = null
  protocol: SequencingProtocol!
  r1FileId: ID = null
  r2FileId: ID = null
  technology: SequencingTechnology!
  nucleicAcid: NucleicAcid!
  hasErcc: Boolean!
  taxonId: ID = null
  primerFileId: ID = null
}

"""An edge in a connection."""
type SequencingReadEdge {
  """A cursor for use in pagination"""
  cursor: String!
  """The item at the end of the edge"""
  node: SequencingRead!
}

type SequencingReadGroupByOptions {
  sample: SampleGroupByOptions
  protocol: SequencingProtocol
  technology: SequencingTechnology
  clearlabsExport: Boolean
  medakaModel: String
  taxon: TaxonGroupByOptions
  primerFile: GenomicRangeGroupByOptions
  id: UUID
  producingRunId: UUID
  ownerUserId: Int
  collectionId: Int
  createdAt: DateTime
  updatedAt: DateTime
}

type SequencingReadMinMaxColumns {
  producingRunId: Int
  ownerUserId: Int
  collectionId: Int
}

type SequencingReadNumericalColumns {
  producingRunId: Int
  ownerUserId: Int
  collectionId: Int
  ownerUserId: Int
  producingRunId: Int
}

input SequencingReadOrderByClause {
  sample: SampleOrderByClause
  protocol: orderBy
  technology: orderBy
  clearlabsExport: orderBy
  medakaModel: orderBy
  taxon: TaxonOrderByClause
  primerFile: GenomicRangeOrderByClause
  id: orderBy
  producingRunId: orderBy
  ownerUserId: orderBy
  collectionId: orderBy
  createdAt: orderBy
  updatedAt: orderBy
}

input SequencingReadUpdateInput {
  collectionId: Int = null
  sampleId: ID = null
  protocol: SequencingProtocol = null
  r1FileId: ID = null
  r2FileId: ID = null
  technology: SequencingTechnology = null
  nucleicAcid: NucleicAcid = null
  hasErcc: Boolean = null
  taxonId: ID = null
  primerFileId: ID = null
}

input SequencingReadWhereClause {
  id: UUIDComparators
  producingRunId: IntComparators
  ownerUserId: IntComparators
  collectionId: IntComparators
  sample: SampleWhereClause
  protocol: SequencingProtocolEnumComparators
  technology: SequencingTechnologyEnumComparators
  nucleicAcid: NucleicAcidEnumComparators
  hasErcc: BoolComparators
  taxon: TaxonWhereClause
  primerFile: GenomicRangeWhereClause
  consensusGenomes: ConsensusGenomeWhereClause
  contigs: ContigWhereClause
}

input SequencingReadWhereClauseMutations {
  id: UUIDComparators
}

enum SequencingTechnology {
  Illumina
  Nanopore
}

input SequencingTechnologyEnumComparators {
  _eq: SequencingTechnology
  _gt: SequencingTechnology
  _gte: SequencingTechnology
  _in: [SequencingTechnology!]
  _is_null: SequencingTechnology
  _lt: SequencingTechnology
  _lte: SequencingTechnology
  _neq: SequencingTechnology
  _nin: [SequencingTechnology!]
}

type SignedURL {
  expiration: Int!
  fields: JSON
  method: String!
  protocol: String!
  url: String!
}

input StrComparators {
  _eq: String
  _gt: String
  _gte: String
  _ilike: String
  _in: [String!]
  _iregex: String
  _is_null: Int
  _like: String
  _lt: String
  _lte: String
  _neq: String
  _nilike: String
  _nin: [String!]
  _niregex: String
  _nlike: String
  _nregex: String
  _regex: String
}

type Taxon implements EntityInterface & Node {
  """The Globally Unique ID of this object"""
  _id: GlobalID!
  id: ID!
  producingRunId: Int
  ownerUserId: Int!
  collectionId: Int!
  wikipediaId: String
  description: String
  commonName: String
  name: String!
  isPhage: Boolean!
  upstreamDatabase(where: UpstreamDatabaseWhereClause = null): UpstreamDatabase
  upstreamDatabaseIdentifier: String!
  level: TaxonLevel!
  consensusGenomes(
    where: ConsensusGenomeWhereClause = null
    """Returns the items in the list that come before the specified cursor."""
    before: String = null
    """Returns the items in the list that come after the specified cursor."""
    after: String = null
    """Returns the items in the list that come before the specified cursor."""
    before: String = null
    """Returns the first n items from the list."""
    first: Int = null
    """Returns the items in the list that come after the specified cursor."""
    last: Int = null
    where: ConsensusGenomeWhereClause = null
  ): ConsensusGenomeConnection!
  consensusGenomesAggregate(where: ConsensusGenomeWhereClause = null): ConsensusGenomeAggregate
  referenceGenomes(
    where: ReferenceGenomeWhereClause = null
    """Returns the items in the list that come before the specified cursor."""
    before: String = null
    """Returns the items in the list that come after the specified cursor."""
    after: String = null
    """Returns the first n items from the list."""
    first: Int = null
    """Returns the items in the list that come after the specified cursor."""
    last: Int = null
  ): ReferenceGenomeConnection!
  referenceGenomesAggregate(where: ReferenceGenomeWhereClause = null): ReferenceGenomeAggregate
  sequencingReads(
    where: SequencingReadWhereClause = null
    """Returns the items in the list that come before the specified cursor."""
    before: String = null
    """Returns the items in the list that come after the specified cursor."""
    after: String = null
    """Returns the items in the list that come before the specified cursor."""
    before: String = null
    """Returns the first n items from the list."""
    first: Int = null
    """Returns the items in the list that come after the specified cursor."""
    last: Int = null
  ): SequencingReadConnection!
  sequencingReadsAggregate(where: SequencingReadWhereClause = null): SequencingReadAggregate
  samples(
    where: SampleWhereClause = null
    """Returns the items in the list that come before the specified cursor."""
    before: String = null
    """Returns the items in the list that come after the specified cursor."""
    after: String = null
    """Returns the first n items from the list."""
    first: Int = null
    """Returns the items in the list that come after the specified cursor."""
    last: Int = null
  ): SampleConnection!
  samplesAggregate(where: SampleWhereClause = null): SampleAggregate
}

type TaxonAggregate {
  aggregate: [TaxonAggregateFunctions!]
}

type TaxonAggregateFunctions {
  avg: TaxonNumericalColumns
  min: TaxonMinMaxColumns
  max: TaxonMinMaxColumns
  stddev: TaxonNumericalColumns
  sum: TaxonNumericalColumns
  variance: TaxonNumericalColumns
  count(distinct: Boolean = false, columns: TaxonCountColumns = null): Int
}

"""A connection to a list of items."""
type TaxonConnection {
  """Contains the nodes in this connection"""
  edges: [TaxonEdge!]!
  """Pagination data for this connection"""
  pageInfo: PageInfo!
}

enum TaxonCountColumns {
  wikipedia_id
  description
  common_name
  name
  is_phage
  upstream_database
  upstream_database_identifier
  level
  tax_parent
  tax_subspecies
  tax_species
  tax_genus
  tax_family
  tax_order
  tax_class
  tax_phylum
  tax_kingdom
  tax_superkingdom
  consensus_genomes
  reference_genomes
  sequencing_reads
  samples
  entity_id
  id
  producing_run_id
  owner_user_id
  collection_id
}

input TaxonCreateInput {
  collectionId: Int!
  wikipediaId: String = null
  description: String = null
  commonName: String = null
  description: String = null
  isPhage: Boolean!
  level: TaxonLevel!
  name: String!
  taxId: Int!
  taxIdClass: Int!
  taxIdFamily: Int!
  taxIdGenus: Int!
  taxIdKingdom: Int!
  taxIdOrder: Int!
  taxIdParent: Int!
  taxIdPhylum: Int!
  taxIdSpecies: Int!
  upstreamDatabaseId: ID!
  upstreamDatabaseIdentifier: String!
  level: TaxonLevel!
}

"""An edge in a connection."""
type TaxonEdge {
  """A cursor for use in pagination"""
  cursor: String!
  """The item at the end of the edge"""
  node: Taxon!
}

type TaxonGroupByOptions {
  wikipediaId: String
  description: String
  commonName: String
  name: String
  isPhage: Boolean
  upstreamDatabase: UpstreamDatabaseGroupByOptions
  upstreamDatabaseIdentifier: String
  level: TaxonLevel
  taxParent: TaxonGroupByOptions
  taxSubspecies: TaxonGroupByOptions
  taxSpecies: TaxonGroupByOptions
  taxGenus: TaxonGroupByOptions
  taxFamily: TaxonGroupByOptions
  taxOrder: TaxonGroupByOptions
  taxClass: TaxonGroupByOptions
  taxPhylum: TaxonGroupByOptions
  taxKingdom: TaxonGroupByOptions
  taxSuperkingdom: TaxonGroupByOptions
  id: UUID
  producingRunId: UUID
  ownerUserId: Int
  collectionId: Int
  createdAt: DateTime
  updatedAt: DateTime
}

enum TaxonLevel {
  family
  genus
  species
}

input TaxonLevelEnumComparators {
  _eq: TaxonLevel
  _gt: TaxonLevel
  _gte: TaxonLevel
  _in: [TaxonLevel!]
  _is_null: TaxonLevel
  _lt: TaxonLevel
  _lte: TaxonLevel
  _neq: TaxonLevel
  _nin: [TaxonLevel!]
}

type TaxonMinMaxColumns {
  producingRunId: Int
  ownerUserId: Int
  collectionId: Int
  wikipediaId: String
  description: String
  commonName: String
  description: String
  name: String
  ownerUserId: Int
  producingRunId: Int
  taxId: Int
  taxIdClass: Int
  taxIdFamily: Int
  taxIdGenus: Int
  taxIdKingdom: Int
  taxIdOrder: Int
  taxIdParent: Int
  taxIdPhylum: Int
  taxIdSpecies: Int
  upstreamDatabaseIdentifier: String
}

type TaxonNumericalColumns {
  producingRunId: Int
  ownerUserId: Int
  collectionId: Int
  ownerUserId: Int
  producingRunId: Int
  taxId: Int
  taxIdClass: Int
  taxIdFamily: Int
  taxIdGenus: Int
  taxIdKingdom: Int
  taxIdOrder: Int
  taxIdParent: Int
  taxIdPhylum: Int
  taxIdSpecies: Int
}

input TaxonOrderByClause {
  wikipediaId: orderBy
  description: orderBy
  commonName: orderBy
  name: orderBy
  isPhage: orderBy
  upstreamDatabase: UpstreamDatabaseOrderByClause
  upstreamDatabaseIdentifier: orderBy
  level: orderBy
  taxParent: orderBy
  taxSubspecies: orderBy
  taxSpecies: orderBy
  taxGenus: orderBy
  taxFamily: orderBy
  taxOrder: orderBy
  taxClass: orderBy
  taxPhylum: orderBy
  taxKingdom: orderBy
  taxSuperkingdom: orderBy
  id: orderBy
  producingRunId: orderBy
  ownerUserId: orderBy
  collectionId: orderBy
  createdAt: orderBy
  updatedAt: orderBy
}

input TaxonUpdateInput {
  collectionId: Int = null
  wikipediaId: String = null
  description: String = null
  commonName: String = null
  name: String = null
  isPhage: Boolean = null
  upstreamDatabaseId: ID = null
  upstreamDatabaseIdentifier: String = null
  level: TaxonLevel = null
}

input TaxonWhereClause {
  id: UUIDComparators
  producingRunId: IntComparators
  ownerUserId: IntComparators
  collectionId: IntComparators
  wikipediaId: StrComparators
  description: StrComparators
  commonName: StrComparators
  consensusGenomes: ConsensusGenomeWhereClause
  description: StrComparators
  id: UUIDComparators
  isPhage: BoolComparators
  level: TaxonLevelEnumComparators
  consensusGenomes: ConsensusGenomeWhereClause
  referenceGenomes: ReferenceGenomeWhereClause
  sequencingReads: SequencingReadWhereClause
  samples: SampleWhereClause
}

input TaxonWhereClauseMutations {
  id: UUIDComparators
}

scalar UUID

input UUIDComparators {
  _eq: UUID
  _gt: UUID
  _gte: UUID
  _in: [UUID!]
  _lt: UUID
  _lte: UUID
  _neq: UUID
  _nin: [UUID!]
}

type UpdateMetadataReponse {
  message: String
  status: String
}

type UpdateSampleName {
  message: String
  status: String
}

type UpdateSampleNotes {
  message: String
  status: String
}

type UpstreamDatabase implements EntityInterface & Node {
  """The Globally Unique ID of this object"""
  _id: GlobalID!
  id: ID!
  producingRunId: Int
  ownerUserId: Int!
  collectionId: Int!
  name: String!
  ownerUserId: Int!
  producingRunId: Int
  taxa(
    where: TaxonWhereClause = null
    """Returns the items in the list that come before the specified cursor."""
    before: String = null
    """Returns the items in the list that come after the specified cursor."""
    after: String = null
    """Returns the items in the list that come before the specified cursor."""
    before: String = null
    """Returns the first n items from the list."""
    first: Int = null
    """Returns the items in the list that come after the specified cursor."""
    last: Int = null
    where: TaxonWhereClause = null
  ): TaxonConnection!
  taxaAggregate(where: TaxonWhereClause = null): TaxonAggregate
  indexes(
    where: IndexFileWhereClause = null
    orderBy: [IndexFileOrderByClause!] = []
    """Returns the items in the list that come before the specified cursor."""
    before: String = null
    """Returns the items in the list that come after the specified cursor."""
    after: String = null
    """Returns the first n items from the list."""
    first: Int = null
    """Returns the items in the list that come after the specified cursor."""
    last: Int = null
  ): IndexFileConnection!
  indexesAggregate(where: IndexFileWhereClause = null): IndexFileAggregate
  accessions(
    where: AccessionWhereClause = null
    orderBy: [AccessionOrderByClause!] = []
    """Returns the items in the list that come before the specified cursor."""
    before: String = null
    """Returns the items in the list that come after the specified cursor."""
    after: String = null
    """Returns the first n items from the list."""
    first: Int = null
    """Returns the items in the list that come after the specified cursor."""
    last: Int = null
  ): AccessionConnection!
  accessionsAggregate(where: AccessionWhereClause = null): AccessionAggregate
  producingRunId: ID
  ownerUserId: Int!
  collectionId: Int!
  createdAt: DateTime!
  updatedAt: DateTime
}

type UpstreamDatabaseAggregate {
  aggregate: [UpstreamDatabaseAggregateFunctions!]
}

type UpstreamDatabaseAggregateFunctions {
  avg: UpstreamDatabaseNumericalColumns
  min: UpstreamDatabaseMinMaxColumns
  max: UpstreamDatabaseMinMaxColumns
  stddev: UpstreamDatabaseNumericalColumns
  sum: UpstreamDatabaseNumericalColumns
  variance: UpstreamDatabaseNumericalColumns
  count(distinct: Boolean = false, columns: UpstreamDatabaseCountColumns = null): Int
}

enum UpstreamDatabaseCountColumns {
  name
  taxa
  entity_id
  id
  producing_run_id
  owner_user_id
  collection_id
}

input UpstreamDatabaseCreateInput {
  name: String!
  producingRunId: ID = null
  collectionId: Int!
}

type UpstreamDatabaseMinMaxColumns {
  producingRunId: Int
  ownerUserId: Int
  collectionId: Int
  createdAt: DateTime
  updatedAt: DateTime
}

type UpstreamDatabaseMinMaxColumns {
  name: String
}

type UpstreamDatabaseNumericalColumns {
  producingRunId: Int
  ownerUserId: Int
  collectionId: Int
  ownerUserId: Int
  producingRunId: Int
}

input UpstreamDatabaseOrderByClause {
  name: orderBy
  id: orderBy
  producingRunId: orderBy
  ownerUserId: orderBy
  collectionId: orderBy
  createdAt: orderBy
  updatedAt: orderBy
}

input UpstreamDatabaseUpdateInput {
  name: String = null
}

input UpstreamDatabaseWhereClause {
  id: UUIDComparators
  producingRunId: IntComparators
  ownerUserId: IntComparators
  collectionId: IntComparators
  name: StrComparators
  taxa: TaxonWhereClause
}

input UpstreamDatabaseWhereClauseMutations {
  id: UUIDComparators
}

type AlignmentConfig {
  createdAt: ISO8601DateTime!
  indexDirSuffix: String
  lineageVersion: String!
  lineageVersionOld: Int
  name: String
  s3Accession2taxidPath: String
  s3DeuterostomeDbPath: String
  s3LineagePath: String
  s3NrDbPath: String
  s3NrLocDbPath: String
  s3NtDbPath: String
  s3NtInfoDbPath: String
  s3NtLocDbPath: String
  s3TaxonBlacklistPath: String
  updatedAt: ISO8601DateTime!
}

input Annotation {
  name: String!
}

type AppConfig {
  key: String!
  value: String!
}

"""
Represents non-fractional signed whole numeric values. Since the value may
exceed the size of a 32-bit integer, it's encoded as a string.
"""
scalar BigInt

"""Autogenerated return type of CreateUser."""
type CreateUserPayload {
  archetypes: String
  email: String
  institution: String
  name: String
  role: Int
  segments: String
  sendActivation: Boolean
}

type DbSample {
  alignmentConfigName: String
  basespaceAccessToken: String
  clientUpdatedAt: ISO8601DateTime
  createdAt: ISO8601DateTime!
  dagVars: String
  doNotProcess: Boolean!
  hostGenomeId: Int
  hostGenomeName: String
  id: Int!
  initialWorkflow: String!
  inputFiles: [InputFile!]!
  maxInputFragments: Int
  name: String
  pipelineBranch: String
  pipelineCommit: String
  pipelineExecutionStrategy: String
  privateUntil: ISO8601DateTime
  projectId: Int
  s3Bowtie2IndexPath: String
  s3PreloadResultPath: String
  s3StarIndexPath: String
  sampleNotes: String
  status: String
  subsample: Int
  updatedAt: ISO8601DateTime!
  uploadError: String
  uploadedFromBasespace: Int!
  useTaxonWhitelist: Boolean!
  userId: Int!
  webCommit: String
}

type DerivedSampleOutput {
  hostGenomeName: String!
  pipelineRun: PipelineRun
  projectName: String!
  summaryStats: SampleSummaryStats
}

type HostGenome {
  createdAt: ISO8601DateTime!
  defaultBackgroundId: Int
  id: Int!
  name: String!
  s3Bowtie2IndexPath: String!
  s3Minimap2IndexPath: String
  s3StarIndexPath: String!
  samplesCount: Int!
  skipDeuteroFilter: Int!
  taxaCategory: String!
  updatedAt: ISO8601DateTime!
  user: User
  userId: Int
}

"""An ISO 8601-encoded datetime"""
scalar ISO8601DateTime

type InputFile {
  createdAt: ISO8601DateTime!
  id: Int!
  name: String
  parts: String
  presignedUrl: String
  sampleId: Int!
  source: String
  sourceType: String
  updatedAt: ISO8601DateTime
  uploadClient: String
}

type MngsRunInfo {
  createdAt: ISO8601DateTime
  finalized: Int
  reportReady: Boolean
  resultStatusDescription: String
  totalRuntime: Int
  withAssembly: Int
}

type Pathogen {
  category: String
  name: String
  taxId: Int
}

type PathogenList {
  citations: [String!]
  createdAt: ISO8601DateTime
  id: ID
  name: String
  pathogens: [Pathogen!]
  updatedAt: ISO8601DateTime
  version: String
}

type PipelineRun {
  adjustedRemainingReads: Int
  alertSent: Boolean!
  alignmentConfig: AlignmentConfig
  alignmentConfigId: Int
  alignmentConfigName: String
  assembled: Int
  compressionRatio: Float
  createdAt: ISO8601DateTime
  dagVars: String
  deprecated: Boolean
  errorMessage: String
  executedAt: ISO8601DateTime
  finalized: Int
  fractionSubsampled: Float
  id: Int!
  jobStatus: String
  knownUserError: String
  maxInputFragments: Int
  pipelineBranch: String
  pipelineCommit: String
  pipelineExecutionStrategy: String
  pipelineVersion: String
  qcPercent: Float
  resultsFinalized: Int
  s3OutputPrefix: String
  sampleId: Int
  sfnExecutionArn: String
  subsample: Int
  timeToFinalized: Int
  timeToResultsFinalized: Int
  totalErccReads: Int
  totalReads: Int
  truncated: Int
  unmappedReads: Int
  updatedAt: ISO8601DateTime!
  useTaxonWhitelist: Boolean!
  wdlVersion: String
}

type Project {
  backgroundFlag: Int
  createdAt: ISO8601DateTime!
  creator: User
  daysToKeepSamplePrivate: Int!
  description: String
  id: Int!
  maxInputFragmentsDefault: Int
  name: String!
  publicAccess: Int!
  samples: [Sample!]
  subsampleDefault: Int
  totalSampleCount: Int!
  updatedAt: ISO8601DateTime!
}

type SampleDetails {
  dbSample: DbSample
  derivedSampleOutput: DerivedSampleOutput
  metadata: SampleMetadata
  mngsRunInfo: MngsRunInfo
  uploader: SampleUploader!
  workflowRunsCountByWorkflow: String
}

type SampleList {
  sampleIds: [Int!]
  samples: [Sample!]!
}

type SampleMetadata {
  collectionDate: String
  collectionLocationV2: String
  nucleotideType: String
  sampleType: String
  waterControl: String
  metadata: [query_SampleMetadata_metadata_items]
  additional_info: query_SampleMetadata_additional_info
}

type SampleReadsStats {
  initialReads: Int
  name: String
  pipelineVersion: String
  sampleId: ID!
  steps: [SampleSteps!]
  wdlVersion: String
}

type SampleReadsStatsList {
  sampleReadsStats: [SampleReadsStats!]!
}

type SampleSteps {
  name: String
  readsAfter: Int
}

type SampleSummaryStats {
  adjustedRemainingReads: Int
  compressionRatio: Float
  insertSizeMean: Float
  insertSizeStandardDeviation: Float
  lastProcessedAt: ISO8601DateTime
  percentRemaining: Float
  qcPercent: Float
  readsAfterCzidDedup: Int
  readsAfterPriceseq: Int
  readsAfterStar: Int
  readsAfterTrimmomatic: Int
  unmappedReads: Int
}

type SampleUploader {
  id: Int!
  name: String
}

type User {
  archetypes: String!
  createdByUserId: BigInt!
  email: String!
  id: ID!
  institution: String!
  name: String!
  role: Int!
  segments: String!
}

type WorkflowRun {
  cachedResults: String
  createdAt: ISO8601DateTime!
  deprecated: Boolean!
  errorMessage: String
  executedAt: ISO8601DateTime
  inputsJson: String
  rerunFrom: Int
  s3OutputPrefix: String
  sample: Sample
  sampleId: Int
  sfnExecutionArn: String
  status: String!
  timeToFinalized: Int
  updatedAt: ISO8601DateTime!
  wdlVersion: String
  workflow: String!
}

type mutation_KickoffWGSWorkflow_items_inputs {
  accession_id: JSON
  accession_name: JSON
  card_version: String
  taxon_id: JSON
  taxon_name: JSON
  technology: String
  wildcard_version: String
}

type mutation_KickoffWGSWorkflow_items_parsed_cached_results {
  quality_metrics: mutation_KickoffWGSWorkflow_items_parsed_cached_results_quality_metrics
}

type mutation_KickoffWGSWorkflow_items_parsed_cached_results_quality_metrics {
  adjusted_remaining_reads: Int
  compression_ratio: Float
  fraction_subsampled: Float
  insert_size_mean: JSON
  insert_size_standard_deviation: JSON
  percent_remaining: Float
  qc_percent: Float
  total_ercc_reads: Int
  total_reads: Int
}

input queryInput_BulkDownloadCGOverview_input_Input {
  authenticityToken: String!
  downloadType: String!
  includeMetadata: Boolean!
  workflow: String!
  workflowRunIds: [Int]!
}

input queryInput_MetadataFields_input_Input {
  authenticityToken: String!
  sampleIds: [String]!
}

input queryInput_SampleMetadata_input_Input @example(value: "{\\"pipelineVersion\\":\\"8.0\\"}") {
  pipelineVersion: String
}

input queryInput_ValidateUserCanDeleteObjects_input_Input @example(value: "{\\"selectedIds\\":[28114,28151],\\"workflow\\":\\"short-read-mngs\\",\\"authenticityToken\\":\\"token\\"}") {
  authenticityToken: String
  selectedIds: [Int]
  workflow: String
}

input queryInput_samples_input_Input {
  orderBy: queryInput_samples_input_orderBy_Input
  sequencingReadsInput: queryInput_samples_input_sequencingReadsInput_Input
  todoRemove: queryInput_samples_input_todoRemove_Input
  where: queryInput_samples_input_where_Input
}

input queryInput_samples_input_orderBy_Input {
  dir: String
  key: String
}

input queryInput_samples_input_sequencingReadsInput_Input {
  where: queryInput_samples_input_sequencingReadsInput_where_Input
}

input queryInput_samples_input_sequencingReadsInput_where_Input {
  consensusGenomes: JSON
}

input queryInput_samples_input_todoRemove_Input {
  domain: String
  limit: Int
  listAllIds: Boolean
  offset: Int
  projectId: String
  taxaLevels: [String]
  taxons: [Int]
  time: [String]
  visibility: String
  workflow: String
}

input queryInput_samples_input_where_Input {
  collectionLocation: queryInput_samples_input_where_collectionLocation_Input
  hostTaxon: queryInput_samples_input_where_hostTaxon_Input
  id: queryInput_samples_input_where_id_Input
  name: queryInput_samples_input_where_name_Input
  sampleType: queryInput_samples_input_where_sampleType_Input
  sequencingReads: queryInput_samples_input_where_sequencingReads_Input
}

input queryInput_samples_input_where_collectionLocation_Input {
  _in: [String]
}

input queryInput_samples_input_where_hostTaxon_Input {
  upstreamDatabaseIdentifier: queryInput_samples_input_where_hostTaxon_upstreamDatabaseIdentifier_Input
}

input queryInput_samples_input_where_hostTaxon_upstreamDatabaseIdentifier_Input {
  _in: [String]
}

input queryInput_samples_input_where_id_Input {
  _in: [String]
}

input queryInput_samples_input_where_name_Input {
  _like: String
}

input queryInput_samples_input_where_sampleType_Input {
  _in: [String]
}

input queryInput_samples_input_where_sequencingReads_Input {
  consensusGenomes: queryInput_samples_input_where_sequencingReads_consensusGenomes_Input
}

input queryInput_samples_input_where_sequencingReads_consensusGenomes_Input {
  taxon: queryInput_samples_input_where_sequencingReads_consensusGenomes_taxon_Input
}

input queryInput_samples_input_where_sequencingReads_consensusGenomes_taxon_Input {
  name: queryInput_samples_input_where_sequencingReads_consensusGenomes_taxon_name_Input
  producingRunId: queryInput_samples_input_where_sequencingReads_consensusGenomes_taxon_producingRunId_Input
}

input queryInput_samples_input_where_sequencingReads_consensusGenomes_taxon_name_Input {
  _in: [String]
}

input queryInput_samples_input_where_sequencingReads_consensusGenomes_taxon_producingRunId_Input {
  _in: [Int]
}

input queryInput_workflowRuns_input_Input {
  entityInputsInput: queryInput_workflowRuns_input_entityInputsInput_Input
  orderBy: queryInput_workflowRuns_input_orderBy_Input
  todoRemove: queryInput_workflowRuns_input_todoRemove_Input
  where: queryInput_workflowRuns_input_where_Input
}

input queryInput_workflowRuns_input_entityInputsInput_Input {
  where: queryInput_workflowRuns_input_entityInputsInput_where_Input
}

input queryInput_workflowRuns_input_entityInputsInput_where_Input {
  fieldName: queryInput_workflowRuns_input_entityInputsInput_where_fieldName_Input
}

input queryInput_workflowRuns_input_entityInputsInput_where_fieldName_Input {
  _eq: String
}

input queryInput_workflowRuns_input_orderBy_Input {
  startedAt: String
}

input queryInput_workflowRuns_input_todoRemove_Input {
  authenticityToken: String
  domain: String
  host: [Int]
  locationV2: [String]
  projectId: String
  search: String
  taxon: [Int]
  taxonLevels: [String]
  time: [String]
  tissue: [String]
  visibility: String
  workflow: String
}

input queryInput_workflowRuns_input_where_Input {
  collectionId: queryInput_workflowRuns_input_where_collectionId_Input
  id: queryInput_workflowRuns_input_where_id_Input
  ownerUserId: queryInput_workflowRuns_input_where_ownerUserId_Input
  startedAt: queryInput_workflowRuns_input_where_startedAt_Input
  workflowVersion: queryInput_workflowRuns_input_where_workflowVersion_Input
}

input queryInput_workflowRuns_input_where_collectionId_Input {
  _in: [Int]
}

input queryInput_workflowRuns_input_where_id_Input {
  _in: [String]
}

input queryInput_workflowRuns_input_where_ownerUserId_Input {
  _eq: Int
}

input queryInput_workflowRuns_input_where_startedAt_Input {
  _gte: String
}

input queryInput_workflowRuns_input_where_workflowVersion_Input {
  workflow: queryInput_workflowRuns_input_where_workflowVersion_workflow_Input
}

input queryInput_workflowRuns_input_where_workflowVersion_workflow_Input {
  name: queryInput_workflowRuns_input_where_workflowVersion_workflow_name_Input
}

input queryInput_workflowRuns_input_where_workflowVersion_workflow_name_Input {
  _in: [String]
}

type query_AmrWorkflowResults_amr_hit_items {
  aro_accession: String
  contig_coverage_breadth: String
  contig_percent_id: String
  contig_species: String
  contigs: String
  cutoff: String
  dpm: Float
  drug_class: String
  gene: String
  gene_family: String
  gene_id: String
  high_level_drug_class: String
  mechanism: String
  model: String
  read_coverage_breadth: String
  read_coverage_depth: String
  read_species: String
  reads: String
  rpm: Float
}

type query_AmrWorkflowResults_metric_amr {
  adjusted_remaining_reads: Int
  compression_ratio: Float
  fraction_subsampled: Float
  insert_size_mean: Int
  insert_size_standard_deviation: Float
  percent_remaining: Float
  qc_percent: Float
  total_ercc_reads: Int
  total_reads: Int
}

type query_Background_other_backgrounds_items {
  created_at: String
  description: String
  id: Int
  mass_normalized: Boolean
  name: String
  public_access: Int
  ready: Int
  updated_at: String
  user_id: Int
  mass_normalized: Boolean
}

type query_bulkDownloads_items {
  id: String
  status: String
  startedAt: String
  rawInputsJson: query_bulkDownloads_items_rawInputsJson
  ownerUserId: String
  file: query_bulkDownloads_items_file
  sampleNames: [JSON]
  analysisCount: Int
  entityInputFileType: String
  entityInputs: [query_bulkDownloads_items_entityInputs_items]
  toDelete: query_bulkDownloads_items_toDelete
}

type query_bulkDownloads_items_rawInputsJson {
  description: String
  downloadType: String
  downloadDisplayName: String
  fileFormat: String
}

type query_bulkDownloads_items_file {
  size: Int
  downloadLink: query_bulkDownloads_items_file_downloadLink
}

type query_bulkDownloads_items_file_downloadLink {
  url: String
}

type query_bulkDownloads_items_entityInputs_items {
  id: String
  name: String
}

type query_bulkDownloads_items_toDelete {
  user_name: String
  log_url: String
  totalSamples: Int
  progress: JSON
}

input queryInput_bulkDownloads_input_Input @example(value: "{\\"searchBy\\":\\"string to search\\",\\"limit\\":10}") {
  searchBy: String
  limit: Int
}

type ConsensusGenomeOverviewRows {
  cgOverviewRows: [[String]]!
}

input queryInput_BulkDownloadCGOverview_input_Input {
  downloadType: String!
  workflowRunIds: [Int]!
  workflow: String!
  includeMetadata: Boolean!
  authenticityToken: String!
}

type query_fedConsensusGenomes_items {
  producingRunId: String
  taxon: query_fedConsensusGenomes_items_taxon
  referenceGenome: query_fedConsensusGenomes_items_referenceGenome
  metrics: query_fedConsensusGenomes_items_metrics
  sequencingRead: query_fedConsensusGenomes_items_sequencingRead
}

type query_fedConsensusGenomes_items_taxon {
  name: String!
}

type query_fedConsensusGenomes_items_referenceGenome {
  accessionId: String
  accessionName: String
}

type query_fedConsensusGenomes_items_metrics {
  coverageDepth: Float
  totalReads: Int
  gcPercent: Float
  refSnps: Int
  percentIdentity: Float
  nActg: Int
  percentGenomeCalled: Float
  nMissing: Int
  nAmbiguous: Int
  referenceGenomeLength: Float
}

type query_fedConsensusGenomes_items_sequencingRead {
  nucleicAcid: String!
  protocol: String
  medakaModel: String
  technology: String!
  taxon: query_fedConsensusGenomes_items_sequencingRead_taxon
  sample: query_fedConsensusGenomes_items_sequencingRead_sample
}

type query_fedConsensusGenomes_items_sequencingRead_taxon {
  name: String!
}

type query_fedConsensusGenomes_items_sequencingRead_sample {
  railsSampleId: Int
  name: String!
  notes: String
  collectionLocation: String!
  sampleType: String!
  waterControl: Boolean
  uploadError: String
  hostOrganism: query_fedConsensusGenomes_items_sequencingRead_sample_hostOrganism
  collection: query_fedConsensusGenomes_items_sequencingRead_sample_collection
  ownerUserId: Float
  ownerUserName: String
  metadatas: query_fedConsensusGenomes_items_sequencingRead_sample_metadatas!
}

type query_fedConsensusGenomes_items_sequencingRead_sample_hostOrganism {
  name: String
}

type query_fedConsensusGenomes_items_sequencingRead_sample_collection {
  name: String
  public: Boolean
}

type query_fedConsensusGenomes_items_sequencingRead_sample_metadatas {
  edges: [query_fedConsensusGenomes_items_sequencingRead_sample_metadatas_edges_items]!
}

type query_fedConsensusGenomes_items_sequencingRead_sample_metadatas_edges_items {
  node: query_fedConsensusGenomes_items_sequencingRead_sample_metadatas_edges_items_node!
}

type query_fedConsensusGenomes_items_sequencingRead_sample_metadatas_edges_items_node {
  fieldName: String!
  value: String!
}

input queryInput_fedConsensusGenomes_input_Input {
  limit: Int
  offset: Int
  where: queryInput_fedConsensusGenomes_input_where_Input
  orderBy: queryInput_fedConsensusGenomes_input_orderBy_Input
  todoRemove: queryInput_fedConsensusGenomes_input_todoRemove_Input
}

input queryInput_fedConsensusGenomes_input_where_Input {
  producingRunId: queryInput_fedConsensusGenomes_input_where_producingRunId_Input
}

input queryInput_fedConsensusGenomes_input_where_producingRunId_Input {
  _in: [String]
}

input queryInput_fedConsensusGenomes_input_orderBy_Input {
  accession: queryInput_fedConsensusGenomes_input_orderBy_accession_Input
  metrics: queryInput_fedConsensusGenomes_input_orderBy_metrics_Input
}

input queryInput_fedConsensusGenomes_input_orderBy_accession_Input {
  accessionId: String
}

input queryInput_fedConsensusGenomes_input_orderBy_metrics_Input {
  coverageDepth: String
  totalReads: String
  gcPercent: String
  refSnps: String
  percentIdentity: String
  nActg: String
  percentGenomeCalled: String
  nMissing: String
  nAmbiguous: String
  referenceGenomeLength: String
}

input queryInput_fedConsensusGenomes_input_todoRemove_Input {
  domain: String
  workflow: String
  projectId: String
  visibility: String
  search: String
  time: [String]
  host: [Int]
  taxaLevels: [String]
  taxons: [Int]
  locationV2: [String]
  tissue: [String]
  orderBy: String
  orderDir: String
}

type ConsensusGenomeWorkflowResults {
  metric_consensus_genome: query_ConsensusGenomeWorkflowResults_metric_consensus_genome
  reference_genome: query_ConsensusGenomeWorkflowResults_reference_genome
}

type query_ConsensusGenomeWorkflowResults_metric_consensus_genome {
  coverage_viz: query_ConsensusGenomeWorkflowResults_metric_consensus_genome_coverage_viz
  ercc_mapped_reads: Int
  gc_percent: Float
  mapped_reads: Int
  n_actg: Int
  n_ambiguous: Int
  n_missing: Int
  percent_genome_called: Float
  percent_identity: Float
  ref_snps: Int
  reference_genome_length: Int
  total_reads: Int
}

type query_ConsensusGenomeWorkflowResults_metric_consensus_genome_coverage_viz {
  coverage: [[Float]]
  coverage_bin_size: Float
  coverage_breadth: Float
  coverage_depth: Float
  max_aligned_length: Int
  total_length: Int
}

type query_ConsensusGenomeWorkflowResults_reference_genome {
  accession_id: String
  accession_name: String
  taxon: query_ConsensusGenomeWorkflowResults_reference_genome_taxon
}

type query_ConsensusGenomeWorkflowResults_reference_genome_taxon {
  id: String
  name: String
}

type query_CoverageVizSummary_items {
  coverage_breadth: JSON
  coverage_depth: JSON
  id: Int
  name: String
  num_contigs: Int
  num_reads: Int
  pipeline_id: Int
  score: Int
}

type query_MetadataFields_items {
  dataType: String
  default_for_new_host_genome: Int
  description: String
  examples: query_MetadataFields_items_examples
  group: String
  host_genome_ids: [Int]
  isBoolean: Boolean
  is_required: Int
  key: String
  name: String
  options: JSON
}

type query_MetadataFields_items_examples {
  all: [String]
}

type query_MngsWorkflowResults__ {
  lineage: [query_MngsWorkflowResults___lineage_items]
}

type query_MngsWorkflowResults___lineage_items {
  name: String
  rank: String
  tax_id: String
}

type query_MngsWorkflowResults_metric_mngs {
  _: query_MngsWorkflowResults_metric_mngs__
  adjusted_remaining_reads: Int
  assembled: Int
  num_reads: Int
  num_reads_after_subsampling: Int
  total_ercc_reads: Int
}

type query_MngsWorkflowResults_metric_mngs__ {
  has_byteranges: Boolean
}

type query_MngsWorkflowResults_taxon_hit_results {
  taxon_hits: [query_MngsWorkflowResults_taxon_hit_results_taxon_hits_items]
}

type query_MngsWorkflowResults_taxon_hit_results_taxon_hits_items {
  _: query_MngsWorkflowResults_taxon_hit_results_taxon_hits_items__
  alignment_length: Float
  base_count: Int
  bpm: Float
  count: Int
  count_type: String
  e_value: Float
  percent_identity: Int
  rpm: Float
  tax_id: Int
}

type query_MngsWorkflowResults_taxon_hit_results_taxon_hits_items__ {
  agg_score: Float
  bg_mean: Float
  bg_mean_mass_normalized: Float
  bg_stdev: Float
  bg_stdev_mass_normalized: Float
  max_z_score: Float
  z_score: Float
}

type query_Pathogens_items {
  tax_id: JSON
}

type query_PipelineData_edges_items {
  files: [query_PipelineData_edges_items_files_items]
  from: query_PipelineData_edges_items_from
  isIntraStage: Boolean
  to: query_PipelineData_edges_items_to
}

type query_PipelineData_edges_items_files_items {
  displayName: String
  url: JSON
}

type query_PipelineData_edges_items_from {
  stageIndex: Int
  stepIndex: Int
}

type query_PipelineData_edges_items_to {
  stageIndex: Int
  stepIndex: Int
}

type query_PipelineData_stages_items {
  jobStatus: String
  name: String
  steps: [query_PipelineData_stages_items_steps_items]
}

type query_PipelineData_stages_items_steps_items {
  description: String
  endTime: JSON
  inputEdges: [Int]
  inputVariables: [query_PipelineData_stages_items_steps_items_inputVariables_items]
  name: String
  outputEdges: [Int]
  outputFiles: [query_PipelineData_stages_items_steps_items_outputFiles_items]
  resources: [JSON]
  startTime: JSON
  status: String
}

type query_PipelineData_stages_items_steps_items_inputVariables_items {
  name: String
  type: String
}

type query_PipelineData_stages_items_steps_items_outputFiles_items {
  displayName: String
  url: JSON
}

type query_SampleMetadata_additional_info {
  editable: Boolean
  ercc_comparison: [query_SampleMetadata_additional_info_ercc_comparison_items]
  host_genome_name: String
  host_genome_taxa_category: String
  name: String
  notes: String
  pipeline_run: query_SampleMetadata_additional_info_pipeline_run
  project_id: Int
  project_name: String
  summary_stats: query_SampleMetadata_additional_info_summary_stats
  upload_date: String
}

type query_SampleMetadata_additional_info_ercc_comparison_items {
  actual: Int
  expected: JSON
  name: String
}

type query_PipelineData_edges_items_from {
  stageIndex: Int
  stepIndex: Int
}

type query_PipelineData_edges_items_files_items {
  displayName: String
  url: JSON
}

type query_fedSamples_items {
  id: String!
  railsSampleId: Int
}

input queryInput_fedSamples_input_Input {
  where: queryInput_fedSamples_input_where_Input
  orderBy: queryInput_fedSamples_input_orderBy_Input
  sequencingReadsInput: queryInput_fedSamples_input_sequencingReadsInput_Input
  todoRemove: queryInput_fedSamples_input_todoRemove_Input
}

input queryInput_fedSamples_input_where_Input {
  id: queryInput_fedSamples_input_where_id_Input
  name: queryInput_fedSamples_input_where_name_Input
  collectionLocation: queryInput_fedSamples_input_where_collectionLocation_Input
  sampleType: queryInput_fedSamples_input_where_sampleType_Input
  hostOrganism: queryInput_fedSamples_input_where_hostOrganism_Input
  sequencingReads: queryInput_fedSamples_input_where_sequencingReads_Input
}

input queryInput_fedSamples_input_where_id_Input {
  _in: [String]
}

input queryInput_fedSamples_input_where_name_Input {
  _like: String
}

input queryInput_fedSamples_input_where_collectionLocation_Input {
  _in: [String]
}

input queryInput_fedSamples_input_where_sampleType_Input {
  _in: [String]
}

input queryInput_fedSamples_input_where_hostOrganism_Input {
  name: queryInput_fedSamples_input_where_hostOrganism_name_Input
}

input queryInput_fedSamples_input_where_hostOrganism_name_Input {
  _in: [String]
}

input queryInput_fedSamples_input_where_sequencingReads_Input {
  taxon: queryInput_fedSamples_input_where_sequencingReads_taxon_Input
  consensusGenomes: queryInput_fedSamples_input_where_sequencingReads_consensusGenomes_Input
}

input queryInput_fedSamples_input_where_sequencingReads_taxon_Input {
  name: queryInput_fedSamples_input_where_sequencingReads_taxon_name_Input
}

input queryInput_fedSamples_input_where_sequencingReads_taxon_name_Input {
  _in: [String]
}

input queryInput_fedSamples_input_where_sequencingReads_consensusGenomes_Input {
  taxon: queryInput_fedSamples_input_where_sequencingReads_consensusGenomes_taxon_Input
}

input queryInput_fedSamples_input_where_sequencingReads_consensusGenomes_taxon_Input {
  name: queryInput_fedSamples_input_where_sequencingReads_consensusGenomes_taxon_name_Input
}

input queryInput_fedSamples_input_where_sequencingReads_consensusGenomes_taxon_name_Input {
  _in: [String]
}

input queryInput_fedSamples_input_orderBy_Input {
  key: String
  dir: String
}

input queryInput_fedSamples_input_sequencingReadsInput_Input {
  where: queryInput_fedSamples_input_sequencingReadsInput_where_Input
}

input queryInput_fedSamples_input_sequencingReadsInput_where_Input {
  taxon: queryInput_fedSamples_input_sequencingReadsInput_where_taxon_Input
  consensusGenomes: queryInput_fedSamples_input_sequencingReadsInput_where_consensusGenomes_Input
}

input queryInput_fedSamples_input_sequencingReadsInput_where_taxon_Input {
  name: queryInput_fedSamples_input_sequencingReadsInput_where_taxon_name_Input
}

input queryInput_fedSamples_input_sequencingReadsInput_where_taxon_name_Input {
  _in: [String]
}

input queryInput_fedSamples_input_sequencingReadsInput_where_consensusGenomes_Input {
  taxon: queryInput_fedSamples_input_sequencingReadsInput_where_consensusGenomes_taxon_Input
}

input queryInput_fedSamples_input_sequencingReadsInput_where_consensusGenomes_taxon_Input {
  name: queryInput_fedSamples_input_sequencingReadsInput_where_consensusGenomes_taxon_name_Input
}

input queryInput_fedSamples_input_sequencingReadsInput_where_consensusGenomes_taxon_name_Input {
  _in: [String]
}

input queryInput_fedSamples_input_todoRemove_Input {
  domain: String
  visibility: String
  time: [String]
  taxaLevels: [String]
  taxons: [Int]
  offset: Int
  limit: Int
  workflow: String
  projectId: String
  listAllIds: Boolean
}

type query_fedSequencingReads_items {
  id: String!
  nucleicAcid: String!
  protocol: String
  medakaModel: String
  technology: String!
  taxon: query_fedSequencingReads_items_taxon
  sample: query_fedSequencingReads_items_sample
  consensusGenomes: query_fedSequencingReads_items_consensusGenomes!
}

type query_fedSequencingReads_items_taxon {
  name: String!
}

type query_fedSequencingReads_items_sample {
  railsSampleId: Int
  name: String!
  notes: String
  collectionLocation: String!
  sampleType: String!
  waterControl: Boolean
  uploadError: String
  hostOrganism: query_fedSequencingReads_items_sample_hostOrganism
  collection: query_fedSequencingReads_items_sample_collection
  ownerUserId: Float
  ownerUserName: String
  metadatas: query_fedSequencingReads_items_sample_metadatas!
}

type query_fedSequencingReads_items_sample_hostOrganism {
  name: String!
}

type query_fedSequencingReads_items_sample_collection {
  name: String
  public: Boolean
}

type query_fedSequencingReads_items_sample_metadatas {
  edges: [query_fedSequencingReads_items_sample_metadatas_edges_items]!
}

type query_fedSequencingReads_items_sample_metadatas_edges_items {
  node: query_fedSequencingReads_items_sample_metadatas_edges_items_node!
}

type query_fedSequencingReads_items_sample_metadatas_edges_items_node {
  fieldName: String!
  value: String!
}

type query_fedSequencingReads_items_consensusGenomes {
  edges: [query_fedSequencingReads_items_consensusGenomes_edges_items]!
}

type query_fedSequencingReads_items_consensusGenomes_edges_items {
  node: query_fedSequencingReads_items_consensusGenomes_edges_items_node!
}

type query_fedSequencingReads_items_consensusGenomes_edges_items_node {
  producingRunId: String
  taxon: query_fedSequencingReads_items_consensusGenomes_edges_items_node_taxon
  referenceGenome: query_fedSequencingReads_items_consensusGenomes_edges_items_node_referenceGenome
  metrics: query_fedSequencingReads_items_consensusGenomes_edges_items_node_metrics
}

type query_fedSequencingReads_items_consensusGenomes_edges_items_node_taxon {
  name: String!
}

type query_fedSequencingReads_items_consensusGenomes_edges_items_node_referenceGenome {
  accessionId: String
  accessionName: String
}

type query_fedSequencingReads_items_consensusGenomes_edges_items_node_metrics {
  coverageDepth: Float
  totalReads: Int
  gcPercent: Float
  refSnps: Int
  percentIdentity: Float
  nActg: Int
  percentGenomeCalled: Float
  nMissing: Int
  nAmbiguous: Int
  referenceGenomeLength: Float
}

input queryInput_fedSequencingReads_input_Input {
  limit: Int
  offset: Int
  where: queryInput_fedSequencingReads_input_where_Input
  orderBy: queryInput_fedSequencingReads_input_orderBy_Input
  consensusGenomesInput: queryInput_fedSequencingReads_input_consensusGenomesInput_Input
  todoRemove: queryInput_fedSequencingReads_input_todoRemove_Input
}

input queryInput_fedSequencingReads_input_where_Input {
  id: queryInput_fedSequencingReads_input_where_id_Input
}

input queryInput_fedSequencingReads_input_where_id_Input {
  _in: [String]
}

input queryInput_fedSequencingReads_input_orderBy_Input {
  protocol: String
  technology: String
  medakaModel: String
  nucleicAcid: String
  sample: queryInput_fedSequencingReads_input_orderBy_sample_Input
}

input queryInput_fedSequencingReads_input_orderBy_sample_Input {
  name: String
  notes: String
  sampleType: String
  waterControl: String
  collectionLocation: String
  hostOrganism: queryInput_fedSequencingReads_input_orderBy_sample_hostOrganism_Input
  metadata: queryInput_fedSequencingReads_input_orderBy_sample_metadata_Input
}

input queryInput_fedSequencingReads_input_orderBy_sample_hostOrganism_Input {
  name: String
}

input queryInput_fedSequencingReads_input_orderBy_sample_metadata_Input {
  fieldName: String
  dir: String
}

input queryInput_fedSequencingReads_input_consensusGenomesInput_Input {
  where: queryInput_fedSequencingReads_input_consensusGenomesInput_where_Input
}

input queryInput_fedSequencingReads_input_consensusGenomesInput_where_Input {
  producingRunId: queryInput_fedSequencingReads_input_consensusGenomesInput_where_producingRunId_Input
}

input queryInput_fedSequencingReads_input_consensusGenomesInput_where_producingRunId_Input {
  _in: [String]
}

input queryInput_fedSequencingReads_input_todoRemove_Input {
  domain: String
  workflow: String
  projectId: String
  visibility: String
  search: String
  time: [String]
  host: [Int]
  taxaLevels: [String]
  taxons: [Int]
  locationV2: [String]
  tissue: [String]
  orderBy: String
  orderDir: String
}

type query_Taxons_items {
  _: query_Taxons_items__
  common_name: JSON
  is_phage: JSON
  level: JSON
  name: JSON
  tax_id: JSON
  tax_id_genus: JSON
}

type query_Taxons_items__ {
  category: JSON
}

type query_UserBlastAnnotations_items {
  annotation: JSON
  tax_id: JSON
}

type query_samples_items {
  id: String
  railsSampleId: Int
  required: JSON
}

type query_workflowRuns_items {
  entityInputs: query_workflowRuns_items_entityInputs!
  id: String!
  ownerUserId: Int!
  startedAt: String
  status: String
  workflowVersion: query_workflowRuns_items_workflowVersion
}

type query_workflowRuns_items_entityInputs {
  edges: [query_workflowRuns_items_entityInputs_edges_items]!
}

type query_workflowRuns_items_entityInputs_edges_items {
  node: query_workflowRuns_items_entityInputs_edges_items_node!
}

type query_workflowRuns_items_entityInputs_edges_items_node {
  entityType: String
}

input queryInput_workflowRuns_input_Input {
  todoRemove: queryInput_workflowRuns_input_todoRemove_Input
  orderBy: queryInput_workflowRuns_input_orderBy_Input
  where: queryInput_workflowRuns_input_where_Input
  entityInputsInput: queryInput_workflowRuns_input_entityInputsInput_Input
}

input queryInput_workflowRuns_input_todoRemove_Input {
  domain: String
  projectId: String
  search: String
  host: [Int]
  locationV2: [String]
  taxon: [Int]
  taxonLevels: [String]
  time: [String]
  tissue: [String]
  visibility: String
  workflow: String
  authenticityToken: String
}

input queryInput_workflowRuns_input_orderBy_Input {
  startedAt: String
  workflowVersion: queryInput_workflowRuns_input_orderBy_workflowVersion_Input
}

input queryInput_workflowRuns_input_orderBy_workflowVersion_Input {
  version: String
  workflow: queryInput_workflowRuns_input_orderBy_workflowVersion_workflow_Input
}

input queryInput_workflowRuns_input_orderBy_workflowVersion_workflow_Input {
  name: String
}

input queryInput_workflowRuns_input_where_Input {
  id: queryInput_workflowRuns_input_where_id_Input
  ownerUserId: queryInput_workflowRuns_input_where_ownerUserId_Input
  startedAt: queryInput_workflowRuns_input_where_startedAt_Input
  collectionId: queryInput_workflowRuns_input_where_collectionId_Input
  workflowVersion: queryInput_workflowRuns_input_where_workflowVersion_Input
}

input queryInput_workflowRuns_input_where_id_Input {
  _in: [String]
}

input queryInput_workflowRuns_input_where_ownerUserId_Input {
  _eq: Int
}

input queryInput_workflowRuns_input_where_startedAt_Input {
  _gte: String
}

input queryInput_workflowRuns_input_where_collectionId_Input {
  _in: [Int]
}

input queryInput_workflowRuns_input_where_workflowVersion_Input {
  workflow: queryInput_workflowRuns_input_where_workflowVersion_workflow_Input
}

input queryInput_workflowRuns_input_where_workflowVersion_workflow_Input {
  name: queryInput_workflowRuns_input_where_workflowVersion_workflow_name_Input
}

input queryInput_workflowRuns_input_where_workflowVersion_workflow_name_Input {
  _in: [String]
}

input queryInput_workflowRuns_input_entityInputsInput_Input {
  where: queryInput_workflowRuns_input_entityInputsInput_where_Input
}

input queryInput_workflowRuns_input_entityInputsInput_where_Input {
  fieldName: queryInput_workflowRuns_input_entityInputsInput_where_fieldName_Input
}

input queryInput_workflowRuns_input_entityInputsInput_where_fieldName_Input {
  _eq: String
}

type query_fedWorkflowRunsAggregate_items {
  collectionId: String!
  mngsRunsCount: Int!
  cgRunsCount: Int!
  amrRunsCount: Int!
}

input queryInput_fedWorkflowRunsAggregate_input_Input {
  where: queryInput_fedWorkflowRunsAggregate_input_where_Input
  todoRemove: queryInput_fedWorkflowRunsAggregate_input_todoRemove_Input
}

input queryInput_fedWorkflowRunsAggregate_input_where_Input {
  id: queryInput_fedWorkflowRunsAggregate_input_where_id_Input
}

input queryInput_fedWorkflowRunsAggregate_input_where_id_Input {
  _in: [String]
}

input queryInput_fedWorkflowRunsAggregate_input_todoRemove_Input {
  projectId: String
  domain: String
  host: [Int]
  locationV2: [String]
  taxonThresholds: [queryInput_fedWorkflowRunsAggregate_input_todoRemove_taxonThresholds_items_Input]
  annotations: [queryInput_fedWorkflowRunsAggregate_input_todoRemove_annotations_items_Input]
  tissue: [String]
  visibility: String
  time: [String]
  taxaLevels: [String]
  taxon: [Int]
  search: String
}

input queryInput_fedWorkflowRunsAggregate_input_todoRemove_taxonThresholds_items_Input {
  metric: String
  count_type: String
  operator: String
  value: String
}

input queryInput_fedWorkflowRunsAggregate_input_todoRemove_annotations_items_Input {
  name: String
}

type ZipLink {
  url: String
  error: String
}

input mutationInput_CreateBulkDownload_input_Input {
  downloadType: String
  workflowRunIds: [String]
  workflow: String
  downloadFormat: String
  authenticityToken: String
}

type DeleteSamples {
  deleted_workflow_ids: [Int]
  error: String
}

input mutationInput_DeleteSamples_input_Input @example(value: "{\\"ids\\":[1],\\"workflow\\":\\"short-read-mngs\\",\\"authenticityToken\\":\\"token\\"}") {
  ids: [Int]
  workflow: String
  authenticityToken: String
}

type UpdateSampleNotes {
  status: String
  message: String
}

input mutationInput_UpdateSampleNotes_input_Input {
  value: String!
  authenticityToken: String!
}

type UpdateSampleName {
  status: String
  message: String
}

type mutation_KickoffWGSWorkflow_items {
  id: String
  status: String
  workflow: String
  wdl_version: String
  executed_at: String
  deprecated: Boolean
  input_error: JSON
  inputs: mutation_KickoffWGSWorkflow_items_inputs
  parsed_cached_results: mutation_KickoffWGSWorkflow_items_parsed_cached_results
  run_finalized: Boolean
}

type mutation_KickoffWGSWorkflow_items_inputs {
  accession_id: JSON
  accession_name: JSON
  taxon_id: JSON
  taxon_name: JSON
  technology: String
  card_version: String
  wildcard_version: String
}

type mutation_KickoffWGSWorkflow_items_parsed_cached_results {
  quality_metrics: mutation_KickoffWGSWorkflow_items_parsed_cached_results_quality_metrics
}

type mutation_KickoffWGSWorkflow_items_parsed_cached_results_quality_metrics {
  total_reads: Int
  qc_percent: Float
  adjusted_remaining_reads: Int
  compression_ratio: Float
  total_ercc_reads: Int
  fraction_subsampled: Float
  insert_size_mean: JSON
  insert_size_standard_deviation: JSON
  percent_remaining: Float
}

input mutationInput_KickoffWGSWorkflow_input_Input @example(value: "{\\"inputs_json\\":{\\"accession_id\\":\\"KX882832.1\\",\\"accession_name\\":\\"Hubei mosquito virus 2 strain mosZJ35453 segment 1 hypothetical protein 1 and hypothetical protein 2 genes, complete cds\\",\\"taxon_id\\":\\"1922926\\",\\"taxon_name\\":\\"Menispermaceae\\",\\"alignment_config_name\\":\\"config_name\\",\\"technology\\":\\"Illumina\\"},\\"workflow\\":\\"amr\\",\\"authenticityToken\\":\\"token\\"}") {
  inputs_json: mutationInput_KickoffWGSWorkflow_input_inputs_json_Input
  workflow: String
  authenticityToken: String
}

input mutationInput_KickoffWGSWorkflow_input_inputs_json_Input {
  accession_id: String
  accession_name: String
  taxon_id: String
  taxon_name: String
  alignment_config_name: String
  technology: String
}

input mutationInput_KickoffAMRWorkflow_input_Input @example(value: "{\\"inputs_json\\":{\\"start_from_mngs\\":true},\\"workflow\\":\\"amr\\",\\"authenticityToken\\":\\"token\\"}") {
  inputs_json: mutationInput_KickoffAMRWorkflow_input_inputs_json_Input
  workflow: String
  authenticityToken: String
}

input mutationInput_KickoffAMRWorkflow_input_inputs_json_Input {
  start_from_mngs: Boolean
}

type UpdateMetadataReponse {
  status: String
  message: String
}

input mutationInput_UpdateMetadata_input_Input {
  field: String!
  value: mutationInput_UpdateMetadata_input_value_Input!
  authenticityToken: String!
}

input mutationInput_UpdateMetadata_input_value_Input @oneOf {
  String: String
  query_SampleMetadata_metadata_items_location_validated_value_oneOf_1_Input: query_SampleMetadata_metadata_items_location_validated_value_oneOf_1_Input
}

input query_SampleMetadata_metadata_items_location_validated_value_oneOf_1_Input {
  id: String
  name: String
}"
`;
